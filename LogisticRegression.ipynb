{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinkashiwakin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import lxml\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import yfinance as yf\n",
    "import stockstats\n",
    "\n",
    "import unicodedata\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, IsolationForest,VotingClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier, tree\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=\"MSFT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_without_absolute = pd.read_pickle('./data/'+target+'/stock_without_absolute.pkl')\n",
    "stock_with_absolute = pd.read_pickle('./data/'+target+'/stock_with_absolute.pkl')\n",
    "\n",
    "label_abs_1d = pd.read_pickle('./data/'+target+'/label_abs_1d.pkl')\n",
    "label_abs_7d = pd.read_pickle('./data/'+target+'/label_abs_7d.pkl')\n",
    "label_abs_30d = pd.read_pickle('./data/'+target+'/label_abs_30d.pkl')\n",
    "\n",
    "label_value_1d = pd.read_pickle('./data/'+target+'/label_value_1d.pkl')\n",
    "label_value_7d = pd.read_pickle('./data/'+target+'/label_value_7d.pkl')\n",
    "label_value_30d = pd.read_pickle('./data/'+target+'/label_value_30d.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_without_absolute.corr().style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_model(classifier, param_grid):\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.1)\n",
    "    grid_model = GridSearchCV(classifier, param_grid=param_grid, cv=cv, n_jobs=-1,verbose=1, scoring='accuracy')\n",
    "    return grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(grid_model, train_data, predicted_test, test_label, predicted_train, train_label, file_name, decision_function, clf_name=\"Classifier\"):\n",
    "    print(\"Results for \", clf_name, \": \")\n",
    "    print()\n",
    "    print(\"The best parameters are %s\" % (grid_model.best_params_))\n",
    "    acc_train = accuracy_score(train_label, predicted_train)\n",
    "    acc_test = accuracy_score(test_label, predicted_test)\n",
    "    print(\"The Train Accuracy  %0.3f\" % (acc_train))\n",
    "    print(\"The Validation Accuracy   %0.3f\" % (grid_model.best_score_))\n",
    "    print(\"The Test Accuracy   %0.3f\" % (acc_test ))\n",
    "    \n",
    "    test_label_roc = np.zeros((len(test_label),2) )\n",
    "    for i,v in enumerate(test_label):\n",
    "        if v > 0.5:\n",
    "            test_label_roc[i,1] = 1\n",
    "        else:\n",
    "            test_label_roc[i,0] = 1\n",
    "    \n",
    "    \n",
    "    print(\"AUC ROC : %0.3f\" %( roc_auc_score(test_label_roc, decision_function)))\n",
    "\n",
    "    print(\"The mean training time of %f\" % (np.mean(grid_model.cv_results_['mean_fit_time'], axis=0)) )\n",
    "    print(\"The mean test time of %f\" % (np.mean(grid_model.cv_results_['mean_score_time'], axis=0)) )\n",
    "    # confusion matrix\n",
    "    print(\"confusion matrix / precision recall scores\")\n",
    "    print ( confusion_matrix(test_label, predicted_test) )\n",
    "    print ( classification_report(test_label, predicted_test))\n",
    "    \n",
    "    f = open(file_name+'.txt','w')\n",
    "    f.write(\"The best parameters are %s\\n\"% (grid_model.best_params_))\n",
    "    f.write(\"The Train Accuracy %0.3f\\n\" % (acc_train))\n",
    "    f.write(\"AUC ROC : %0.3f\\n\" %( roc_auc_score(test_label_roc, decision_function) ))\n",
    "\n",
    "    f.write(\"The Validation Accuracy %0.3f\\n\" % (grid_model.best_score_))\n",
    "    f.write(\"The Test Accuracy %0.3f\\n\" % (acc_test ))\n",
    "    f.write( str(confusion_matrix(test_label, predicted_test)) + \"\\n\")\n",
    "    f.write( str(classification_report(test_label, predicted_test)) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_1d_model_param = None\n",
    "best_7d_model_param = None\n",
    "best_30d_model_param = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改這些地方： train_data, label, filename, clfname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  Logistic Regression : \n",
      "\n",
      "The best parameters are {'solver': 'saga'}\n",
      "The Train Accuracy  0.570\n",
      "The Validation Accuracy   0.510\n",
      "The Test Accuracy   0.490\n",
      "AUC ROC : 0.520\n",
      "The mean training time of 0.320416\n",
      "The mean test time of 0.000888\n",
      "confusion matrix / precision recall scores\n",
      "[[90 44]\n",
      " [83 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.67      0.59       134\n",
      "           1       0.42      0.28      0.34       115\n",
      "\n",
      "    accuracy                           0.49       249\n",
      "   macro avg       0.47      0.47      0.46       249\n",
      "weighted avg       0.47      0.49      0.47       249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinkashiwakin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# stock_with_absolute, predict 1 day trend \n",
    "rfc = LogisticRegression(n_jobs=-1) # classifier\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "\n",
    "# param to grid search\n",
    "param_grid = dict(solver=solver)\n",
    "\n",
    "# train data and label\n",
    "train_data = stock_with_absolute\n",
    "label = label_abs_1d\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, shuffle=True)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "rfc_model = create_grid_model(rfc, param_grid)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_test = rfc_model.predict(X_test)\n",
    "predicted_train = rfc_model.predict(X_train)\n",
    "decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "result(rfc_model, train_data, predicted_test, y_test, predicted_train, y_train, \n",
    "       \"./results/\"+target+\"/lgr_with_ABS_pred_1_d\", decision_function, clf_name=\"Logistic Regression\")\n",
    "\n",
    "best_1d_model_param = rfc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stock_without_absolute, predict 1 day trend \n",
    "# rfc = LogisticRegression(n_jobs=-1) # classifier\n",
    "# solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "\n",
    "# # param to grid search\n",
    "# param_grid = dict(solver=solver)\n",
    "\n",
    "# # train data and label\n",
    "# train_data = stock_without_absolute\n",
    "# label = label_abs_1d\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, random_state=42)\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# rfc_model = create_grid_model(rfc, param_grid)\n",
    "# rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# predicted_test = rfc_model.predict(X_test)\n",
    "# predicted_train = rfc_model.predict(X_train)\n",
    "# decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "# result(rfc_model, train_data, predicted_test, y_test, predicted_train, y_train, \n",
    "#        \"./results/lgr_without_ABS_pred_1_d\", decision_function, clf_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Results for  Logistic Regression : \n",
      "\n",
      "The best parameters are {'solver': 'lbfgs'}\n",
      "The Train Accuracy  0.605\n",
      "The Validation Accuracy   0.563\n",
      "The Test Accuracy   0.598\n",
      "AUC ROC : 0.619\n",
      "The mean training time of 0.318198\n",
      "The mean test time of 0.000745\n",
      "confusion matrix / precision recall scores\n",
      "[[114  23]\n",
      " [ 77  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       137\n",
      "           1       0.60      0.31      0.41       112\n",
      "\n",
      "    accuracy                           0.60       249\n",
      "   macro avg       0.60      0.57      0.55       249\n",
      "weighted avg       0.60      0.60      0.57       249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "# stock_with_absolute, predict 7 day trend \n",
    "rfc = LogisticRegression(n_jobs=-1) # classifier\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "\n",
    "# param to grid search\n",
    "param_grid = dict(solver=solver)\n",
    "\n",
    "# train data and label\n",
    "train_data = stock_with_absolute\n",
    "label = label_abs_7d\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, shuffle=True)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "rfc_model = create_grid_model(rfc, param_grid)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_test = rfc_model.predict(X_test)\n",
    "predicted_train = rfc_model.predict(X_train)\n",
    "decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "result(rfc_model, train_data, predicted_test, y_test, predicted_train, y_train, \n",
    "       \"./results/\"+target+\"/lgr_with_ABS_pred_7_d\", decision_function, clf_name=\"Logistic Regression\")\n",
    "best_7d_model_param = rfc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stock_without_absolute, predict 7 day trend \n",
    "# rfc = LogisticRegression(n_jobs=-1) # classifier\n",
    "# solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "\n",
    "# # param to grid search\n",
    "# param_grid = dict(solver=solver)\n",
    "\n",
    "# # train data and label\n",
    "# train_data = stock_without_absolute\n",
    "# label = label_abs_7d\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, random_state=42)\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# rfc_model = create_grid_model(rfc, param_grid)\n",
    "# rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# predicted_test = rfc_model.predict(X_test)\n",
    "# predicted_train = rfc_model.predict(X_train)\n",
    "# decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "# result(rfc_model, train_data, predicted_test, y_test, predicted_train, y_train, \n",
    "#        \"./results/lgr_without_ABS_pred_7_d\", decision_function, clf_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  Logistic Regression : \n",
      "\n",
      "The best parameters are {'solver': 'newton-cg'}\n",
      "The Train Accuracy  0.706\n",
      "The Validation Accuracy   0.667\n",
      "The Test Accuracy   0.647\n",
      "AUC ROC : 0.647\n",
      "The mean training time of 0.280239\n",
      "The mean test time of 0.000756\n",
      "confusion matrix / precision recall scores\n",
      "[[143  22]\n",
      " [ 66  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76       165\n",
      "           1       0.45      0.21      0.29        84\n",
      "\n",
      "    accuracy                           0.65       249\n",
      "   macro avg       0.57      0.54      0.53       249\n",
      "weighted avg       0.61      0.65      0.60       249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "# stock_with_absolute, predict 30 day trend \n",
    "rfc = LogisticRegression(n_jobs=-1) # classifier\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "\n",
    "# param to grid search\n",
    "param_grid = dict(solver=solver)\n",
    "\n",
    "# train data and label\n",
    "train_data = stock_with_absolute\n",
    "label = label_abs_30d\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, shuffle=True)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "rfc_model = create_grid_model(rfc, param_grid)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_test = rfc_model.predict(X_test)\n",
    "predicted_train = rfc_model.predict(X_train)\n",
    "decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "result(rfc_model, train_data, predicted_test, y_test, predicted_train, y_train, \n",
    "       \"./results/\"+target+\"/lgr_with_ABS_pred_30_d\", decision_function, clf_name=\"Logistic Regression\")\n",
    "best_30d_model_param = rfc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stock_without_absolute, predict 30 day trend \n",
    "# rfc = LogisticRegression(n_jobs=-1) # classifier\n",
    "# solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "\n",
    "# # param to grid search\n",
    "# param_grid = dict(solver=solver)\n",
    "\n",
    "# # train data and label\n",
    "# train_data = stock_without_absolute\n",
    "# label = label_abs_30d\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, random_state=42)\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# rfc_model = create_grid_model(rfc, param_grid)\n",
    "# rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# predicted_test = rfc_model.predict(X_test)\n",
    "# predicted_train = rfc_model.predict(X_train)\n",
    "# decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "# result(rfc_model, train_data, predicted_test, y_test, predicted_train, y_train, \n",
    "#        \"./results/lgr_without_ABS_pred_30_d\", decision_function, clf_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinkashiwakin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Accuracy  0.562\n",
      "The Test Accuracy   0.502\n",
      "{'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinkashiwakin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Accuracy  0.616\n",
      "The Test Accuracy   0.550\n",
      "{'solver': 'newton-cg'}\n",
      "The Train Accuracy  0.703\n",
      "The Test Accuracy   0.675\n"
     ]
    }
   ],
   "source": [
    "best_list = [best_1d_model_param, best_7d_model_param,  best_30d_model_param]\n",
    "labels = [label_abs_1d, label_abs_7d, label_abs_30d]\n",
    "file_name = [\"LR_1d\", \"LR_7d\", \"LR_30d\"]\n",
    "\n",
    "for index, best_parameters in enumerate(best_list):\n",
    "    print(best_parameters)\n",
    "    rfc = LogisticRegression(**best_parameters)\n",
    "\n",
    "    # train data and label\n",
    "    train_data = stock_with_absolute\n",
    "    label = labels[index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, label, test_size=0.1, shuffle=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    predicted_test = rfc.predict(X_test)\n",
    "    predicted_train = rfc.predict(X_train)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, predicted_train)\n",
    "    acc_test = accuracy_score(y_test, predicted_test)\n",
    "    print(\"The Train Accuracy  %0.3f\" % (acc_train))\n",
    "    print(\"The Test Accuracy   %0.3f\" % (acc_test ))\n",
    "    pickle.dump(rfc, open('./backend/'+target+'/LR/'+file_name[index]+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
