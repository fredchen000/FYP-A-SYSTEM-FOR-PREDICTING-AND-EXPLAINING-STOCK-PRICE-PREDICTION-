{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# using stockstats library to get indicators\n",
    "import stockstats\n",
    "import yfinance as yf\n",
    "\n",
    "data = yf.download(\"AAPL\", start=\"2009-11-01\", end=\"2019-12-31\")\n",
    "data['high_low_diff_ratio'] = (data['High'] - data['Low']) / data['Close']\n",
    "data['open_close_diff_ratio'] = (data['Open'] - data['Close']) / data['Close']\n",
    "\n",
    "stock = stockstats.StockDataFrame.retype(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Behavior of MACDH calculation has changed as of July 2017 - it is now 1/2 of previous calculated values\n"
     ]
    }
   ],
   "source": [
    "stock[['close_1_d', 'close_-1_d', 'close_-7_d', 'close_-30_d','change', \n",
    "'open_delta','close_delta','volume_delta', 'close_-1_r','close_-6_r', \n",
    "'boll', 'boll_ub', 'boll_lb', 'boll_-1_d', 'boll_ub_-1_d', 'boll_lb_-1_d' ,\n",
    "'kdjk_9','kdjd_9','kdjj_9', 'macd','macds','macdh', 'rsi_6', 'rsi_14', 'rsi_30',\n",
    "'wr_6', 'wr_12', 'cci', 'atr', 'dma', 'vr']]\n",
    "\n",
    "stock_slice = pd.DataFrame(stock)\n",
    "stock_slice = stock_slice.drop(stock.index[:42])\n",
    "stock_slice = stock_slice.drop(stock.index[-1])\n",
    "stock_slice['boll_k_diff'] = stock_slice['boll'] - stock_slice['close']\n",
    "# stock_slice = stock_slice[['close_1_d', 'close_7_d', 'close_30_d','change', 'open_delta','close_delta','volume_delta', 'high_low_diff_ratio', \n",
    "# 'open_close_diff_ratio','close_-1_r','close_-6_r','kdjk','kdjd','kdjj', 'macd','macds', \n",
    "# 'macdh', 'rsi_6', 'rsi_14', 'rsi_30','wr_6', 'wr_12', 'cci', 'atr', 'dma', 'vr', 'boll_-1_d','boll_ub_-1_d', 'boll_lb_-1_d', \n",
    "# 'boll_k_diff' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>high_low_diff_ratio</th>\n",
       "      <th>open_close_diff_ratio</th>\n",
       "      <th>close_1_s</th>\n",
       "      <th>close_1_d</th>\n",
       "      <th>...</th>\n",
       "      <th>middle</th>\n",
       "      <th>middle_14_sma</th>\n",
       "      <th>cci</th>\n",
       "      <th>tr</th>\n",
       "      <th>atr</th>\n",
       "      <th>close_10_sma</th>\n",
       "      <th>close_50_sma</th>\n",
       "      <th>dma</th>\n",
       "      <th>vr</th>\n",
       "      <th>boll_k_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.490000</td>\n",
       "      <td>30.642857</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.572857</td>\n",
       "      <td>26.538483</td>\n",
       "      <td>123432400</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>-0.002710</td>\n",
       "      <td>30.625713</td>\n",
       "      <td>-0.052856</td>\n",
       "      <td>...</td>\n",
       "      <td>30.518571</td>\n",
       "      <td>28.956259</td>\n",
       "      <td>104.544323</td>\n",
       "      <td>0.538570</td>\n",
       "      <td>0.592501</td>\n",
       "      <td>29.460715</td>\n",
       "      <td>28.562824</td>\n",
       "      <td>0.897891</td>\n",
       "      <td>106.156549</td>\n",
       "      <td>-1.991928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.657143</td>\n",
       "      <td>30.798571</td>\n",
       "      <td>30.464285</td>\n",
       "      <td>30.625713</td>\n",
       "      <td>26.584366</td>\n",
       "      <td>150476200</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>30.138571</td>\n",
       "      <td>0.487143</td>\n",
       "      <td>...</td>\n",
       "      <td>30.629523</td>\n",
       "      <td>29.147585</td>\n",
       "      <td>94.633916</td>\n",
       "      <td>0.334286</td>\n",
       "      <td>0.573262</td>\n",
       "      <td>29.731429</td>\n",
       "      <td>28.609708</td>\n",
       "      <td>1.121721</td>\n",
       "      <td>121.337062</td>\n",
       "      <td>-1.894356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.625713</td>\n",
       "      <td>30.747143</td>\n",
       "      <td>30.107143</td>\n",
       "      <td>30.138571</td>\n",
       "      <td>26.161509</td>\n",
       "      <td>138040000</td>\n",
       "      <td>0.021235</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>30.082857</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>...</td>\n",
       "      <td>30.330952</td>\n",
       "      <td>29.324456</td>\n",
       "      <td>66.376669</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>0.578219</td>\n",
       "      <td>29.913429</td>\n",
       "      <td>28.643683</td>\n",
       "      <td>1.269746</td>\n",
       "      <td>116.329575</td>\n",
       "      <td>-1.249928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>30.285715</td>\n",
       "      <td>29.864286</td>\n",
       "      <td>30.082857</td>\n",
       "      <td>26.113146</td>\n",
       "      <td>119282800</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>30.282858</td>\n",
       "      <td>-0.200001</td>\n",
       "      <td>...</td>\n",
       "      <td>30.077620</td>\n",
       "      <td>29.479388</td>\n",
       "      <td>43.383588</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.566606</td>\n",
       "      <td>30.059429</td>\n",
       "      <td>28.674969</td>\n",
       "      <td>1.384460</td>\n",
       "      <td>115.360861</td>\n",
       "      <td>-1.046286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>30.042856</td>\n",
       "      <td>30.285715</td>\n",
       "      <td>29.865715</td>\n",
       "      <td>30.282858</td>\n",
       "      <td>26.286753</td>\n",
       "      <td>111902700</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>-0.007925</td>\n",
       "      <td>30.015715</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>...</td>\n",
       "      <td>30.144763</td>\n",
       "      <td>29.667075</td>\n",
       "      <td>42.188356</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.555776</td>\n",
       "      <td>30.200571</td>\n",
       "      <td>28.709179</td>\n",
       "      <td>1.491392</td>\n",
       "      <td>132.308467</td>\n",
       "      <td>-1.145001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>282.230011</td>\n",
       "      <td>282.649994</td>\n",
       "      <td>278.559998</td>\n",
       "      <td>279.440002</td>\n",
       "      <td>278.778381</td>\n",
       "      <td>68994500</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>-4.559998</td>\n",
       "      <td>...</td>\n",
       "      <td>280.216665</td>\n",
       "      <td>271.774046</td>\n",
       "      <td>91.189096</td>\n",
       "      <td>4.089996</td>\n",
       "      <td>4.005587</td>\n",
       "      <td>275.224997</td>\n",
       "      <td>258.718600</td>\n",
       "      <td>16.506397</td>\n",
       "      <td>101.907226</td>\n",
       "      <td>-9.369005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>280.529999</td>\n",
       "      <td>284.250000</td>\n",
       "      <td>280.369995</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>283.327576</td>\n",
       "      <td>24643000</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>-0.012218</td>\n",
       "      <td>284.269989</td>\n",
       "      <td>-0.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>282.873332</td>\n",
       "      <td>273.520474</td>\n",
       "      <td>103.723098</td>\n",
       "      <td>4.809998</td>\n",
       "      <td>4.063045</td>\n",
       "      <td>276.932996</td>\n",
       "      <td>259.674400</td>\n",
       "      <td>17.258596</td>\n",
       "      <td>117.064732</td>\n",
       "      <td>-12.818002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>284.690002</td>\n",
       "      <td>284.890015</td>\n",
       "      <td>282.920013</td>\n",
       "      <td>284.269989</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>12119700</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>289.910004</td>\n",
       "      <td>-5.640015</td>\n",
       "      <td>...</td>\n",
       "      <td>284.026672</td>\n",
       "      <td>275.100236</td>\n",
       "      <td>100.973703</td>\n",
       "      <td>1.970001</td>\n",
       "      <td>3.913542</td>\n",
       "      <td>278.511993</td>\n",
       "      <td>260.642400</td>\n",
       "      <td>17.869594</td>\n",
       "      <td>112.926237</td>\n",
       "      <td>-12.192992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>284.820007</td>\n",
       "      <td>289.980011</td>\n",
       "      <td>284.700012</td>\n",
       "      <td>289.910004</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>23280300</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>-0.017557</td>\n",
       "      <td>289.799988</td>\n",
       "      <td>0.110016</td>\n",
       "      <td>...</td>\n",
       "      <td>288.196676</td>\n",
       "      <td>276.776189</td>\n",
       "      <td>130.167647</td>\n",
       "      <td>5.710022</td>\n",
       "      <td>4.041862</td>\n",
       "      <td>280.425995</td>\n",
       "      <td>261.734200</td>\n",
       "      <td>18.691795</td>\n",
       "      <td>113.439713</td>\n",
       "      <td>-16.552007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>291.119995</td>\n",
       "      <td>293.970001</td>\n",
       "      <td>288.119995</td>\n",
       "      <td>289.799988</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>36566500</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>291.519989</td>\n",
       "      <td>-1.720001</td>\n",
       "      <td>...</td>\n",
       "      <td>290.629995</td>\n",
       "      <td>278.273332</td>\n",
       "      <td>139.544458</td>\n",
       "      <td>5.850006</td>\n",
       "      <td>4.171015</td>\n",
       "      <td>282.259995</td>\n",
       "      <td>262.842800</td>\n",
       "      <td>19.417195</td>\n",
       "      <td>107.415536</td>\n",
       "      <td>-15.343991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2514 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close   adj close  \\\n",
       "Date                                                                     \n",
       "2010-01-04   30.490000   30.642857   30.340000   30.572857   26.538483   \n",
       "2010-01-05   30.657143   30.798571   30.464285   30.625713   26.584366   \n",
       "2010-01-06   30.625713   30.747143   30.107143   30.138571   26.161509   \n",
       "2010-01-07   30.250000   30.285715   29.864286   30.082857   26.113146   \n",
       "2010-01-08   30.042856   30.285715   29.865715   30.282858   26.286753   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2019-12-20  282.230011  282.649994  278.559998  279.440002  278.778381   \n",
       "2019-12-23  280.529999  284.250000  280.369995  284.000000  283.327576   \n",
       "2019-12-24  284.690002  284.890015  282.920013  284.269989  283.596924   \n",
       "2019-12-26  284.820007  289.980011  284.700012  289.910004  289.223602   \n",
       "2019-12-27  291.119995  293.970001  288.119995  289.799988  289.113831   \n",
       "\n",
       "               volume  high_low_diff_ratio  open_close_diff_ratio   close_1_s  \\\n",
       "Date                                                                            \n",
       "2010-01-04  123432400             0.009906              -0.002710   30.625713   \n",
       "2010-01-05  150476200             0.010915               0.001026   30.138571   \n",
       "2010-01-06  138040000             0.021235               0.016163   30.082857   \n",
       "2010-01-07  119282800             0.014009               0.005556   30.282858   \n",
       "2010-01-08  111902700             0.013869              -0.007925   30.015715   \n",
       "...               ...                  ...                    ...         ...   \n",
       "2019-12-20   68994500             0.014636               0.009984  284.000000   \n",
       "2019-12-23   24643000             0.013662              -0.012218  284.269989   \n",
       "2019-12-24   12119700             0.006930               0.001478  289.910004   \n",
       "2019-12-26   23280300             0.018213              -0.017557  289.799988   \n",
       "2019-12-27   36566500             0.020186               0.004555  291.519989   \n",
       "\n",
       "            close_1_d  ...      middle  middle_14_sma         cci        tr  \\\n",
       "Date                   ...                                                    \n",
       "2010-01-04  -0.052856  ...   30.518571      28.956259  104.544323  0.538570   \n",
       "2010-01-05   0.487143  ...   30.629523      29.147585   94.633916  0.334286   \n",
       "2010-01-06   0.055714  ...   30.330952      29.324456   66.376669  0.639999   \n",
       "2010-01-07  -0.200001  ...   30.077620      29.479388   43.383588  0.421429   \n",
       "2010-01-08   0.267143  ...   30.144763      29.667075   42.188356  0.420000   \n",
       "...               ...  ...         ...            ...         ...       ...   \n",
       "2019-12-20  -4.559998  ...  280.216665     271.774046   91.189096  4.089996   \n",
       "2019-12-23  -0.269989  ...  282.873332     273.520474  103.723098  4.809998   \n",
       "2019-12-24  -5.640015  ...  284.026672     275.100236  100.973703  1.970001   \n",
       "2019-12-26   0.110016  ...  288.196676     276.776189  130.167647  5.710022   \n",
       "2019-12-27  -1.720001  ...  290.629995     278.273332  139.544458  5.850006   \n",
       "\n",
       "                 atr  close_10_sma  close_50_sma        dma          vr  \\\n",
       "Date                                                                      \n",
       "2010-01-04  0.592501     29.460715     28.562824   0.897891  106.156549   \n",
       "2010-01-05  0.573262     29.731429     28.609708   1.121721  121.337062   \n",
       "2010-01-06  0.578219     29.913429     28.643683   1.269746  116.329575   \n",
       "2010-01-07  0.566606     30.059429     28.674969   1.384460  115.360861   \n",
       "2010-01-08  0.555776     30.200571     28.709179   1.491392  132.308467   \n",
       "...              ...           ...           ...        ...         ...   \n",
       "2019-12-20  4.005587    275.224997    258.718600  16.506397  101.907226   \n",
       "2019-12-23  4.063045    276.932996    259.674400  17.258596  117.064732   \n",
       "2019-12-24  3.913542    278.511993    260.642400  17.869594  112.926237   \n",
       "2019-12-26  4.041862    280.425995    261.734200  18.691795  113.439713   \n",
       "2019-12-27  4.171015    282.259995    262.842800  19.417195  107.415536   \n",
       "\n",
       "            boll_k_diff  \n",
       "Date                     \n",
       "2010-01-04    -1.991928  \n",
       "2010-01-05    -1.894356  \n",
       "2010-01-06    -1.249928  \n",
       "2010-01-07    -1.046286  \n",
       "2010-01-08    -1.145001  \n",
       "...                 ...  \n",
       "2019-12-20    -9.369005  \n",
       "2019-12-23   -12.818002  \n",
       "2019-12-24   -12.192992  \n",
       "2019-12-26   -16.552007  \n",
       "2019-12-27   -15.343991  \n",
       "\n",
       "[2514 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = stock_slice['close_1_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['open', 'high', 'low', 'close', 'adj close', 'volume',\n",
      "       'high_low_diff_ratio', 'open_close_diff_ratio', 'close_-1_d',\n",
      "       'close_-7_d', 'close_-30_d', 'change', 'open_delta', 'close_delta',\n",
      "       'volume_delta', 'close_-1_r', 'close_-6_r', 'close_20_sma',\n",
      "       'close_20_mstd', 'boll', 'boll_ub', 'boll_lb', 'boll_-1_d',\n",
      "       'boll_ub_-1_d', 'boll_lb_-1_d', 'rsv_9', 'kdjk_9', 'kdjd_9', 'kdjj_9',\n",
      "       'macd', 'macds', 'macdh', 'rsi_6', 'rsi_14', 'rsi_30', 'wr_6', 'wr_12',\n",
      "       'cci', 'tr', 'atr', 'close_10_sma', 'close_50_sma', 'dma', 'vr',\n",
      "       'boll_k_diff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "stock_slice = stock_slice.drop(['close_1_d','close_1_s', 'close_-1_s', 'close_-7_s', 'close_-30_s', 'rs_6', 'rs_14', 'rs_30', 'middle',\n",
    "                                'boll_-1_s', 'boll_ub_-1_s', 'boll_lb_-1_s', 'middle_14_sma'], axis=1)\n",
    "# stock_slice = stock_slice.drop(['open', 'high', 'low', 'close','adj close', 'volume', 'close_10_sma', 'close_50_sma'], axis=1)\n",
    "print(stock_slice.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ref: https://medium.com/@daniel820710/%E5%88%A9%E7%94%A8keras%E5%BB%BA%E6%A7%8Blstm%E6%A8%A1%E5%9E%8B-%E4%BB%A5stock-prediction-%E7%82%BA%E4%BE%8B-1-67456e0a0b\n",
    "'''\n",
    "RANDOM_SEED = 10\n",
    "def build_batch(train, label, pastDay=30, futureDay=5):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureDay-pastDay):\n",
    "        X_train.append(np.array(train[i:i+pastDay]))\n",
    "        Y_train.append(np.array(label[i+pastDay:i+pastDay+futureDay]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = stock_slice[:2300]\n",
    "train_label = label[:2300]\n",
    "test_data = stock_slice[2300:]\n",
    "test_label = label[2300:]\n",
    "\n",
    "# train_data, test_data, train_label, test_label = train_test_split(stock_slice, label, test_size=0.15, random_state=RANDOM_SEED, shuffle=True)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(train_data)\n",
    "x_test = min_max_scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAST_DAYS = 1\n",
    "X_train_batches, Y_train_batches = build_batch(x_train, train_label, PAST_DAYS, 1)\n",
    "X_test_batches, Y_test_batches = build_batch(x_test, test_label, PAST_DAYS, 1)\n",
    "\n",
    "#get validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_batches, Y_train_batches, test_size=0.15, random_state=RANDOM_SEED, shuffle=True)\n",
    "\n",
    "# y_train = y_train[..., np.newaxis]\n",
    "# y_valid = y_valid[..., np.newaxis]\n",
    "\n",
    "# Y_test_batches = Y_test_batches[..., np.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1953, 1, 45)\n",
      "X_valid shape:  (345, 1, 45)\n",
      "y_train shape:  (1953, 1)\n",
      "y_valid shape:  (345, 1)\n",
      "X_test_batches shape:  (212, 1, 45)\n",
      "Y_test_batches shape:  (212, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_valid shape: ', X_valid.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_valid shape: ', y_valid.shape)\n",
    "print('X_test_batches shape: ', X_test_batches.shape)\n",
    "print('Y_test_batches shape: ', Y_test_batches.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildToOneModel(shape):\n",
    "    model = Sequential()\n",
    "#     model.add(LSTM(75, input_length=shape[1], input_dim=shape[2]))\n",
    "#     model.add(LSTM(50, input_length=shape[1], input_dim=shape[2]))\n",
    "#     model.add(LSTM(50, return_sequences= False))\n",
    "#     model.add(Dense(40))\n",
    "#     model.add(Dense(30))\n",
    "#     model.add(Dense(15))\n",
    "#     model.add(Dense(1))    # or use model.add(Dense(1))\n",
    "    model.add(LSTM(75, return_sequences=True, input_length=shape[1], input_dim=shape[2]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(75, return_sequences= False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 50)             19200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 40,701\n",
      "Trainable params: 40,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1953 samples, validate on 345 samples\n",
      "Epoch 1/1000\n",
      "1953/1953 [==============================] - 1s 625us/step - loss: 9170.9531 - val_loss: 3791.2450\n",
      "Epoch 2/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 2617.0422 - val_loss: 2223.7772\n",
      "Epoch 3/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 1878.9905 - val_loss: 950.8554\n",
      "Epoch 4/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 540.0292 - val_loss: 221.0548\n",
      "Epoch 5/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 159.9144 - val_loss: 82.8055\n",
      "Epoch 6/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 71.1683 - val_loss: 47.2327\n",
      "Epoch 7/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 44.5037 - val_loss: 34.9314\n",
      "Epoch 8/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 31.7128 - val_loss: 21.9665\n",
      "Epoch 9/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 23.1718 - val_loss: 17.7213\n",
      "Epoch 10/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 18.1226 - val_loss: 15.7523\n",
      "Epoch 11/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 15.6262 - val_loss: 14.0241\n",
      "Epoch 12/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 13.2846 - val_loss: 12.0123\n",
      "Epoch 13/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 12.2016 - val_loss: 9.3541\n",
      "Epoch 14/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 10.6614 - val_loss: 10.4529\n",
      "Epoch 15/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 9.9838 - val_loss: 8.0776\n",
      "Epoch 16/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 9.3598 - val_loss: 8.1738\n",
      "Epoch 17/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 9.0518 - val_loss: 9.3424\n",
      "Epoch 18/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 9.1857 - val_loss: 9.2903\n",
      "Epoch 19/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 8.6136 - val_loss: 10.9928\n",
      "Epoch 20/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 9.3667 - val_loss: 10.4376\n",
      "Epoch 21/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 8.4790 - val_loss: 10.6380\n",
      "Epoch 22/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 9.7007 - val_loss: 8.4337\n",
      "Epoch 23/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 8.1472 - val_loss: 7.9384\n",
      "Epoch 24/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 7.7097 - val_loss: 8.8179\n",
      "Epoch 25/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 7.7698 - val_loss: 8.5520\n",
      "Epoch 26/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 8.2023 - val_loss: 9.4427\n",
      "Epoch 27/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 8.0353 - val_loss: 8.4997\n",
      "Epoch 28/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 7.4557 - val_loss: 8.3415\n",
      "Epoch 29/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 8.2169 - val_loss: 8.7998\n",
      "Epoch 30/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 7.7040 - val_loss: 8.5862\n",
      "Epoch 31/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 8.3354 - val_loss: 11.1601\n",
      "Epoch 32/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 7.4016 - val_loss: 8.1335\n",
      "Epoch 33/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 7.8236 - val_loss: 8.7158\n",
      "Epoch 34/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 7.9445 - val_loss: 7.7659\n",
      "Epoch 35/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 7.4215 - val_loss: 8.8173\n",
      "Epoch 36/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 7.3890 - val_loss: 9.0858\n",
      "Epoch 37/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 7.3168 - val_loss: 9.8014\n",
      "Epoch 38/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 7.2955 - val_loss: 9.4759\n",
      "Epoch 39/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 7.3961 - val_loss: 8.7504\n",
      "Epoch 40/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 7.5721 - val_loss: 10.3856\n",
      "Epoch 41/1000\n",
      "1953/1953 [==============================] - 0s 120us/step - loss: 7.4006 - val_loss: 7.9142\n",
      "Epoch 42/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 7.2173 - val_loss: 7.9671\n",
      "Epoch 43/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 7.6777 - val_loss: 8.7244\n",
      "Epoch 44/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.7365 - val_loss: 10.4370\n",
      "Epoch 45/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 7.4373 - val_loss: 7.8004\n",
      "Epoch 46/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 7.0514 - val_loss: 8.1850\n",
      "Epoch 47/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.9273 - val_loss: 9.1995\n",
      "Epoch 48/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 7.8522 - val_loss: 10.4021\n",
      "Epoch 49/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 8.8492 - val_loss: 7.6724\n",
      "Epoch 50/1000\n",
      "1953/1953 [==============================] - 0s 112us/step - loss: 7.3838 - val_loss: 8.3547\n",
      "Epoch 51/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.7352 - val_loss: 8.7105\n",
      "Epoch 52/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 7.8772 - val_loss: 8.6574\n",
      "Epoch 53/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 7.0500 - val_loss: 8.8314\n",
      "Epoch 54/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.0405 - val_loss: 12.9749\n",
      "Epoch 55/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 7.7554 - val_loss: 10.2612\n",
      "Epoch 56/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.0065 - val_loss: 8.3723\n",
      "Epoch 57/1000\n",
      "1953/1953 [==============================] - 0s 115us/step - loss: 7.1848 - val_loss: 7.4686\n",
      "Epoch 58/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 7.4137 - val_loss: 9.2297\n",
      "Epoch 59/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.7677 - val_loss: 8.0361\n",
      "Epoch 60/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.6286 - val_loss: 9.0602\n",
      "Epoch 61/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.8251 - val_loss: 7.4472\n",
      "Epoch 62/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.0809 - val_loss: 8.1609\n",
      "Epoch 63/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.8364 - val_loss: 7.4945\n",
      "Epoch 64/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.3947 - val_loss: 7.8136\n",
      "Epoch 65/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 7.2175 - val_loss: 10.1184\n",
      "Epoch 66/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 7.2295 - val_loss: 11.7382\n",
      "Epoch 67/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 7.5204 - val_loss: 8.1497\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.7159 - val_loss: 8.4396\n",
      "Epoch 69/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.9206 - val_loss: 8.4816\n",
      "Epoch 70/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.9396 - val_loss: 8.5697\n",
      "Epoch 71/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 7.1843 - val_loss: 9.8163\n",
      "Epoch 72/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 7.0987 - val_loss: 7.4759\n",
      "Epoch 73/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.0619 - val_loss: 8.2899\n",
      "Epoch 74/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.7724 - val_loss: 8.1145\n",
      "Epoch 75/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.3585 - val_loss: 8.0144\n",
      "Epoch 76/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.7038 - val_loss: 8.2855\n",
      "Epoch 77/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.6002 - val_loss: 7.7871\n",
      "Epoch 78/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.4686 - val_loss: 7.4405\n",
      "Epoch 79/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.5258 - val_loss: 8.2819\n",
      "Epoch 80/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.3984 - val_loss: 9.9117\n",
      "Epoch 81/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.7883 - val_loss: 8.9499\n",
      "Epoch 82/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.5838 - val_loss: 8.0013\n",
      "Epoch 83/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.6095 - val_loss: 7.6540\n",
      "Epoch 84/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.9837 - val_loss: 9.2503\n",
      "Epoch 85/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 7.3624 - val_loss: 7.7479\n",
      "Epoch 86/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.4685 - val_loss: 7.6802\n",
      "Epoch 87/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 7.1397 - val_loss: 8.3556\n",
      "Epoch 88/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.6408 - val_loss: 8.3177\n",
      "Epoch 89/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.1688 - val_loss: 8.5046\n",
      "Epoch 90/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.9720 - val_loss: 7.8176\n",
      "Epoch 91/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 6.6331 - val_loss: 7.7325\n",
      "Epoch 92/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.7926 - val_loss: 10.9372\n",
      "Epoch 93/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.1736 - val_loss: 7.2290\n",
      "Epoch 94/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.6519 - val_loss: 9.2817\n",
      "Epoch 95/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.9945 - val_loss: 8.6628\n",
      "Epoch 96/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.5803 - val_loss: 8.0940\n",
      "Epoch 97/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.5965 - val_loss: 9.1197\n",
      "Epoch 98/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.7542 - val_loss: 8.5756\n",
      "Epoch 99/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 7.1502 - val_loss: 8.0072\n",
      "Epoch 100/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.6420 - val_loss: 7.8774\n",
      "Epoch 101/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.7203 - val_loss: 7.8773\n",
      "Epoch 102/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.5728 - val_loss: 9.0663\n",
      "Epoch 103/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.5847 - val_loss: 9.8872\n",
      "Epoch 104/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.5665 - val_loss: 7.5184\n",
      "Epoch 105/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.8142 - val_loss: 7.8627\n",
      "Epoch 106/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.2563 - val_loss: 7.5173\n",
      "Epoch 107/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 7.0010 - val_loss: 8.4884\n",
      "Epoch 108/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.4412 - val_loss: 7.8194\n",
      "Epoch 109/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.6412 - val_loss: 8.0923\n",
      "Epoch 110/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.3637 - val_loss: 10.4273\n",
      "Epoch 111/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.3339 - val_loss: 12.2872\n",
      "Epoch 112/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.5359 - val_loss: 7.5272\n",
      "Epoch 113/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.3025 - val_loss: 8.0126\n",
      "Epoch 114/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.5921 - val_loss: 8.2186\n",
      "Epoch 115/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.5038 - val_loss: 9.4225\n",
      "Epoch 116/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 7.0382 - val_loss: 8.8291\n",
      "Epoch 117/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 6.2636 - val_loss: 7.7082\n",
      "Epoch 118/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.3615 - val_loss: 7.4981\n",
      "Epoch 119/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1848 - val_loss: 10.9188\n",
      "Epoch 120/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.4374 - val_loss: 7.7683\n",
      "Epoch 121/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.5178 - val_loss: 8.1119\n",
      "Epoch 122/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.6235 - val_loss: 9.6489\n",
      "Epoch 123/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.2083 - val_loss: 9.4472\n",
      "Epoch 124/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.5273 - val_loss: 8.0381\n",
      "Epoch 125/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.6155 - val_loss: 8.4575\n",
      "Epoch 126/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.1218 - val_loss: 7.2929\n",
      "Epoch 127/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.2701 - val_loss: 7.6972\n",
      "Epoch 128/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.3485 - val_loss: 8.0335\n",
      "Epoch 129/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.3084 - val_loss: 8.1811\n",
      "Epoch 130/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 6.0435 - val_loss: 7.8188\n",
      "Epoch 131/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.1845 - val_loss: 8.8131\n",
      "Epoch 132/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.5114 - val_loss: 6.9965\n",
      "Epoch 133/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.4799 - val_loss: 8.3618\n",
      "Epoch 134/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.2724 - val_loss: 8.3356\n",
      "Epoch 135/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 6.8808 - val_loss: 8.0216\n",
      "Epoch 136/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 5.9881 - val_loss: 7.7915\n",
      "Epoch 137/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 6.1222 - val_loss: 7.2136\n",
      "Epoch 138/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1574 - val_loss: 7.7463\n",
      "Epoch 139/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.9655 - val_loss: 7.0765\n",
      "Epoch 140/1000\n",
      "1953/1953 [==============================] - 0s 120us/step - loss: 5.8798 - val_loss: 8.7381\n",
      "Epoch 141/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 6.2202 - val_loss: 10.4901\n",
      "Epoch 142/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.3247 - val_loss: 8.7930\n",
      "Epoch 143/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1276 - val_loss: 7.4536\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.3972 - val_loss: 7.7393\n",
      "Epoch 145/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 6.3363 - val_loss: 7.6074\n",
      "Epoch 146/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 6.0184 - val_loss: 7.8929\n",
      "Epoch 147/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 6.3982 - val_loss: 8.6040\n",
      "Epoch 148/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.7538 - val_loss: 9.1374\n",
      "Epoch 149/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 6.0799 - val_loss: 7.2687\n",
      "Epoch 150/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.0381 - val_loss: 8.0359\n",
      "Epoch 151/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 6.3915 - val_loss: 7.1766\n",
      "Epoch 152/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 6.2106 - val_loss: 8.6510\n",
      "Epoch 153/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.7978 - val_loss: 7.5226\n",
      "Epoch 154/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 6.1236 - val_loss: 7.6396\n",
      "Epoch 155/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.6704 - val_loss: 8.0434\n",
      "Epoch 156/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 6.6009 - val_loss: 8.5586\n",
      "Epoch 157/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.4345 - val_loss: 8.6688\n",
      "Epoch 158/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.7411 - val_loss: 8.5880\n",
      "Epoch 159/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.8900 - val_loss: 7.2826\n",
      "Epoch 160/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.0910 - val_loss: 7.8296\n",
      "Epoch 161/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.9562 - val_loss: 8.0265\n",
      "Epoch 162/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.8896 - val_loss: 9.6593\n",
      "Epoch 163/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1558 - val_loss: 7.6876\n",
      "Epoch 164/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.9510 - val_loss: 7.3487\n",
      "Epoch 165/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 6.2805 - val_loss: 7.8154\n",
      "Epoch 166/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.8861 - val_loss: 7.2786\n",
      "Epoch 167/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.8930 - val_loss: 7.0104\n",
      "Epoch 168/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.3738 - val_loss: 9.8386\n",
      "Epoch 169/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.3415 - val_loss: 7.0168\n",
      "Epoch 170/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.7140 - val_loss: 8.2820\n",
      "Epoch 171/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.4266 - val_loss: 9.5038\n",
      "Epoch 172/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.4664 - val_loss: 8.6743\n",
      "Epoch 173/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.8874 - val_loss: 8.1781\n",
      "Epoch 174/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.0730 - val_loss: 8.2362\n",
      "Epoch 175/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.4359 - val_loss: 8.3134\n",
      "Epoch 176/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.4033 - val_loss: 8.4325\n",
      "Epoch 177/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.0699 - val_loss: 7.2745\n",
      "Epoch 178/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.8898 - val_loss: 7.9404\n",
      "Epoch 179/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.7965 - val_loss: 7.0799\n",
      "Epoch 180/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.5856 - val_loss: 7.9274\n",
      "Epoch 181/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.0622 - val_loss: 9.4629\n",
      "Epoch 182/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 6.5827 - val_loss: 11.7090\n",
      "Epoch 183/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.8716 - val_loss: 7.2653\n",
      "Epoch 184/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.8773 - val_loss: 7.7570\n",
      "Epoch 185/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.8977 - val_loss: 7.2472\n",
      "Epoch 186/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.3073 - val_loss: 6.9807\n",
      "Epoch 187/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.2533 - val_loss: 9.0215\n",
      "Epoch 188/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.1137 - val_loss: 7.7682\n",
      "Epoch 189/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 6.3422 - val_loss: 7.8739\n",
      "Epoch 190/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 7.0666 - val_loss: 7.1142\n",
      "Epoch 191/1000\n",
      "1953/1953 [==============================] - 0s 119us/step - loss: 5.7742 - val_loss: 12.1865\n",
      "Epoch 192/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.8136 - val_loss: 7.0816\n",
      "Epoch 193/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.9788 - val_loss: 8.2188\n",
      "Epoch 194/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.8729 - val_loss: 7.7951\n",
      "Epoch 195/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.2354 - val_loss: 8.3325\n",
      "Epoch 196/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.0670 - val_loss: 7.2600\n",
      "Epoch 197/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.1622 - val_loss: 10.1381\n",
      "Epoch 198/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 6.5353 - val_loss: 7.8995\n",
      "Epoch 199/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.9996 - val_loss: 7.6811\n",
      "Epoch 200/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 6.2602 - val_loss: 7.4763\n",
      "Epoch 201/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 6.1813 - val_loss: 8.4319\n",
      "Epoch 202/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.8314 - val_loss: 8.3940\n",
      "Epoch 203/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 6.1457 - val_loss: 7.1694\n",
      "Epoch 204/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 6.0757 - val_loss: 7.8726\n",
      "Epoch 205/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.4898 - val_loss: 7.3415\n",
      "Epoch 206/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.6920 - val_loss: 7.1247\n",
      "Epoch 207/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.0271 - val_loss: 8.3686\n",
      "Epoch 208/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.8658 - val_loss: 7.1431\n",
      "Epoch 209/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 6.0403 - val_loss: 8.0813\n",
      "Epoch 210/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 6.1112 - val_loss: 7.5891\n",
      "Epoch 211/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 6.0194 - val_loss: 7.3064\n",
      "Epoch 212/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.8290 - val_loss: 7.0655\n",
      "Epoch 213/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.1143 - val_loss: 7.1216\n",
      "Epoch 214/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.7366 - val_loss: 7.5130\n",
      "Epoch 215/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.8578 - val_loss: 8.1917\n",
      "Epoch 216/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.9125 - val_loss: 7.8301\n",
      "Epoch 217/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 5.9060 - val_loss: 7.1881\n",
      "Epoch 218/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.5337 - val_loss: 7.3966\n",
      "Epoch 219/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.9661 - val_loss: 7.0531\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.5574 - val_loss: 8.7579\n",
      "Epoch 221/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.5868 - val_loss: 7.1158\n",
      "Epoch 222/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.7844 - val_loss: 8.0869\n",
      "Epoch 223/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.9896 - val_loss: 8.1440\n",
      "Epoch 224/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.0827 - val_loss: 8.9210\n",
      "Epoch 225/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.8747 - val_loss: 8.6356\n",
      "Epoch 226/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 6.5540 - val_loss: 7.1416\n",
      "Epoch 227/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.9767 - val_loss: 8.3173\n",
      "Epoch 228/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 5.7602 - val_loss: 7.4077\n",
      "Epoch 229/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 5.8218 - val_loss: 7.5196\n",
      "Epoch 230/1000\n",
      "1953/1953 [==============================] - 0s 124us/step - loss: 5.9320 - val_loss: 7.0359\n",
      "Epoch 231/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 5.7292 - val_loss: 9.0559\n",
      "Epoch 232/1000\n",
      "1953/1953 [==============================] - 0s 96us/step - loss: 6.5084 - val_loss: 15.9954\n",
      "Epoch 233/1000\n",
      "1953/1953 [==============================] - 0s 97us/step - loss: 6.8434 - val_loss: 8.6338\n",
      "Epoch 234/1000\n",
      "1953/1953 [==============================] - 0s 97us/step - loss: 6.4087 - val_loss: 6.8820\n",
      "Epoch 235/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.6411 - val_loss: 7.3310\n",
      "Epoch 236/1000\n",
      "1953/1953 [==============================] - 0s 97us/step - loss: 5.7142 - val_loss: 7.7410\n",
      "Epoch 237/1000\n",
      "1953/1953 [==============================] - 0s 97us/step - loss: 5.8636 - val_loss: 7.2150\n",
      "Epoch 238/1000\n",
      "1953/1953 [==============================] - 0s 96us/step - loss: 5.5705 - val_loss: 7.8117\n",
      "Epoch 239/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.8858 - val_loss: 8.1071\n",
      "Epoch 240/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.4352 - val_loss: 9.0720\n",
      "Epoch 241/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.8709 - val_loss: 7.7747\n",
      "Epoch 242/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 6.2040 - val_loss: 7.8565\n",
      "Epoch 243/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.7358 - val_loss: 10.3990\n",
      "Epoch 244/1000\n",
      "1953/1953 [==============================] - 0s 96us/step - loss: 6.0894 - val_loss: 9.1924\n",
      "Epoch 245/1000\n",
      "1953/1953 [==============================] - 0s 97us/step - loss: 5.9550 - val_loss: 7.9787\n",
      "Epoch 246/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 6.0482 - val_loss: 10.4671\n",
      "Epoch 247/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 6.2947 - val_loss: 8.1214\n",
      "Epoch 248/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.5608 - val_loss: 6.9293\n",
      "Epoch 249/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.5306 - val_loss: 6.9009\n",
      "Epoch 250/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.3977 - val_loss: 7.3763\n",
      "Epoch 251/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 5.6373 - val_loss: 8.0224\n",
      "Epoch 252/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.8340 - val_loss: 6.9126\n",
      "Epoch 253/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.8604 - val_loss: 7.7877\n",
      "Epoch 254/1000\n",
      "1953/1953 [==============================] - 0s 114us/step - loss: 5.7371 - val_loss: 8.7982\n",
      "Epoch 255/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 5.8739 - val_loss: 7.2429\n",
      "Epoch 256/1000\n",
      "1953/1953 [==============================] - 0s 115us/step - loss: 5.7878 - val_loss: 6.5163\n",
      "Epoch 257/1000\n",
      "1953/1953 [==============================] - 0s 123us/step - loss: 5.8003 - val_loss: 7.8746\n",
      "Epoch 258/1000\n",
      "1953/1953 [==============================] - 0s 115us/step - loss: 5.7961 - val_loss: 9.3041\n",
      "Epoch 259/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 5.5831 - val_loss: 7.1919\n",
      "Epoch 260/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.7778 - val_loss: 8.1532\n",
      "Epoch 261/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.7806 - val_loss: 6.8932\n",
      "Epoch 262/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.6964 - val_loss: 8.0072\n",
      "Epoch 263/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.9809 - val_loss: 9.0677\n",
      "Epoch 264/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.7792 - val_loss: 10.6917\n",
      "Epoch 265/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.8425 - val_loss: 6.5487\n",
      "Epoch 266/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5493 - val_loss: 7.8533\n",
      "Epoch 267/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 5.6715 - val_loss: 7.4444\n",
      "Epoch 268/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.6196 - val_loss: 17.1976\n",
      "Epoch 269/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 5.8199 - val_loss: 6.9493\n",
      "Epoch 270/1000\n",
      "1953/1953 [==============================] - 0s 114us/step - loss: 5.4682 - val_loss: 7.8504\n",
      "Epoch 271/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.8785 - val_loss: 8.4025\n",
      "Epoch 272/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.9500 - val_loss: 6.7269\n",
      "Epoch 273/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5566 - val_loss: 6.4503\n",
      "Epoch 274/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.5208 - val_loss: 7.1765\n",
      "Epoch 275/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.2957 - val_loss: 6.8443\n",
      "Epoch 276/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.3699 - val_loss: 7.4405\n",
      "Epoch 277/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.7824 - val_loss: 8.2721\n",
      "Epoch 278/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 5.6716 - val_loss: 7.9957\n",
      "Epoch 279/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.7442 - val_loss: 6.9441\n",
      "Epoch 280/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.8004 - val_loss: 8.1498\n",
      "Epoch 281/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.5796 - val_loss: 6.8053\n",
      "Epoch 282/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.6978 - val_loss: 7.7964\n",
      "Epoch 283/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.6482 - val_loss: 7.0214\n",
      "Epoch 284/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1299 - val_loss: 7.7821\n",
      "Epoch 285/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.4520 - val_loss: 6.5948\n",
      "Epoch 286/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.4927 - val_loss: 7.7646\n",
      "Epoch 287/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.5251 - val_loss: 8.2092\n",
      "Epoch 288/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.4278 - val_loss: 8.6481\n",
      "Epoch 289/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.9521 - val_loss: 7.3660\n",
      "Epoch 290/1000\n",
      "1953/1953 [==============================] - 0s 118us/step - loss: 5.6792 - val_loss: 6.5796\n",
      "Epoch 291/1000\n",
      "1953/1953 [==============================] - 0s 121us/step - loss: 5.4639 - val_loss: 6.4639\n",
      "Epoch 292/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.8209 - val_loss: 8.3421\n",
      "Epoch 293/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.7423 - val_loss: 6.7789\n",
      "Epoch 294/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.3882 - val_loss: 6.1832\n",
      "Epoch 295/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5372 - val_loss: 9.8486\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5162 - val_loss: 6.9823\n",
      "Epoch 297/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.4506 - val_loss: 7.0572\n",
      "Epoch 298/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.4649 - val_loss: 7.2086\n",
      "Epoch 299/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.9496 - val_loss: 7.5537\n",
      "Epoch 300/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 6.1501 - val_loss: 8.5871\n",
      "Epoch 301/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1376 - val_loss: 7.9487\n",
      "Epoch 302/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.5979 - val_loss: 7.1918\n",
      "Epoch 303/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.5402 - val_loss: 6.6271\n",
      "Epoch 304/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.4616 - val_loss: 7.6055\n",
      "Epoch 305/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.4336 - val_loss: 7.0547\n",
      "Epoch 306/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.4720 - val_loss: 7.0319\n",
      "Epoch 307/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.7813 - val_loss: 6.8079\n",
      "Epoch 308/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3271 - val_loss: 7.1084\n",
      "Epoch 309/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.5722 - val_loss: 9.7782\n",
      "Epoch 310/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.1197 - val_loss: 6.5548\n",
      "Epoch 311/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3608 - val_loss: 8.8463\n",
      "Epoch 312/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.5191 - val_loss: 7.8815\n",
      "Epoch 313/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.4685 - val_loss: 6.6328\n",
      "Epoch 314/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.5023 - val_loss: 8.6474\n",
      "Epoch 315/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.5368 - val_loss: 7.8951\n",
      "Epoch 316/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 6.0776 - val_loss: 9.4976\n",
      "Epoch 317/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.6144 - val_loss: 7.2600\n",
      "Epoch 318/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.9775 - val_loss: 7.3771\n",
      "Epoch 319/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3789 - val_loss: 6.9755\n",
      "Epoch 320/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.4132 - val_loss: 7.5389\n",
      "Epoch 321/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.4240 - val_loss: 6.7498\n",
      "Epoch 322/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.2577 - val_loss: 7.0548\n",
      "Epoch 323/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.2117 - val_loss: 6.5274\n",
      "Epoch 324/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1582 - val_loss: 7.7957\n",
      "Epoch 325/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.2864 - val_loss: 9.1519\n",
      "Epoch 326/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.2409 - val_loss: 7.8229\n",
      "Epoch 327/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.4006 - val_loss: 7.4690\n",
      "Epoch 328/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.5437 - val_loss: 7.4103\n",
      "Epoch 329/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.2695 - val_loss: 6.8025\n",
      "Epoch 330/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3438 - val_loss: 6.3572\n",
      "Epoch 331/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 6.3169 - val_loss: 7.4646\n",
      "Epoch 332/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.4833 - val_loss: 9.8650\n",
      "Epoch 333/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3669 - val_loss: 7.6992\n",
      "Epoch 334/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.6310 - val_loss: 6.8380\n",
      "Epoch 335/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.7645 - val_loss: 7.7526\n",
      "Epoch 336/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.4157 - val_loss: 6.3897\n",
      "Epoch 337/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.7871 - val_loss: 6.4139\n",
      "Epoch 338/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.3101 - val_loss: 6.3332\n",
      "Epoch 339/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.3156 - val_loss: 7.0239\n",
      "Epoch 340/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.9807 - val_loss: 7.0288\n",
      "Epoch 341/1000\n",
      "1953/1953 [==============================] - 0s 117us/step - loss: 5.6066 - val_loss: 6.9397\n",
      "Epoch 342/1000\n",
      "1953/1953 [==============================] - 0s 115us/step - loss: 5.5268 - val_loss: 6.4128\n",
      "Epoch 343/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.4614 - val_loss: 7.6089\n",
      "Epoch 344/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.2592 - val_loss: 6.3435\n",
      "Epoch 345/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1199 - val_loss: 7.0453\n",
      "Epoch 346/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.3137 - val_loss: 6.0076\n",
      "Epoch 347/1000\n",
      "1953/1953 [==============================] - 0s 118us/step - loss: 5.6199 - val_loss: 7.0266\n",
      "Epoch 348/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.9955 - val_loss: 8.5337\n",
      "Epoch 349/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.8328 - val_loss: 7.7002\n",
      "Epoch 350/1000\n",
      "1953/1953 [==============================] - 0s 120us/step - loss: 5.8234 - val_loss: 6.6123\n",
      "Epoch 351/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 5.2555 - val_loss: 6.3012\n",
      "Epoch 352/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.6908 - val_loss: 9.4626\n",
      "Epoch 353/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.1037 - val_loss: 6.3868\n",
      "Epoch 354/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.2755 - val_loss: 6.3898\n",
      "Epoch 355/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.5282 - val_loss: 6.8513\n",
      "Epoch 356/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.3353 - val_loss: 7.6454\n",
      "Epoch 357/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 5.3223 - val_loss: 9.2116\n",
      "Epoch 358/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.7841 - val_loss: 7.2558\n",
      "Epoch 359/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.3897 - val_loss: 6.9029\n",
      "Epoch 360/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.0224 - val_loss: 6.7816\n",
      "Epoch 361/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5666 - val_loss: 6.6021\n",
      "Epoch 362/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.2159 - val_loss: 6.1519\n",
      "Epoch 363/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.2443 - val_loss: 6.8269\n",
      "Epoch 364/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.3573 - val_loss: 6.7528\n",
      "Epoch 365/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.4596 - val_loss: 6.9769\n",
      "Epoch 366/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.7776 - val_loss: 6.7939\n",
      "Epoch 367/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.9002 - val_loss: 6.3212\n",
      "Epoch 368/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.2749 - val_loss: 6.1807\n",
      "Epoch 369/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.0528 - val_loss: 6.7439\n",
      "Epoch 370/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.4051 - val_loss: 6.7447\n",
      "Epoch 371/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.3702 - val_loss: 7.2738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5685 - val_loss: 7.4126\n",
      "Epoch 373/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1521 - val_loss: 7.0270\n",
      "Epoch 374/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3667 - val_loss: 6.6110\n",
      "Epoch 375/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.4856 - val_loss: 7.1340\n",
      "Epoch 376/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3861 - val_loss: 8.3326\n",
      "Epoch 377/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.5873 - val_loss: 7.5751\n",
      "Epoch 378/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.5026 - val_loss: 6.6220\n",
      "Epoch 379/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.2390 - val_loss: 9.0955\n",
      "Epoch 380/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.2023 - val_loss: 6.4941\n",
      "Epoch 381/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.3578 - val_loss: 6.7300\n",
      "Epoch 382/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5752 - val_loss: 7.2423\n",
      "Epoch 383/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.0870 - val_loss: 8.5203\n",
      "Epoch 384/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.3340 - val_loss: 7.3002\n",
      "Epoch 385/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3882 - val_loss: 6.7402\n",
      "Epoch 386/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.6115 - val_loss: 8.7663\n",
      "Epoch 387/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.1483 - val_loss: 5.8263\n",
      "Epoch 388/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8478 - val_loss: 6.7196\n",
      "Epoch 389/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.4248 - val_loss: 6.3466\n",
      "Epoch 390/1000\n",
      "1953/1953 [==============================] - 0s 119us/step - loss: 5.5613 - val_loss: 6.8915\n",
      "Epoch 391/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.1975 - val_loss: 6.0037\n",
      "Epoch 392/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.1974 - val_loss: 9.8061\n",
      "Epoch 393/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.6123 - val_loss: 6.2465\n",
      "Epoch 394/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.0905 - val_loss: 6.9415\n",
      "Epoch 395/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.3108 - val_loss: 5.6839\n",
      "Epoch 396/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.1965 - val_loss: 6.7757\n",
      "Epoch 397/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.9672 - val_loss: 7.0631\n",
      "Epoch 398/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.8289 - val_loss: 6.2933\n",
      "Epoch 399/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0147 - val_loss: 6.2805\n",
      "Epoch 400/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.2934 - val_loss: 7.4719\n",
      "Epoch 401/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.2300 - val_loss: 6.3438\n",
      "Epoch 402/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.2900 - val_loss: 9.9411\n",
      "Epoch 403/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.9575 - val_loss: 7.5241\n",
      "Epoch 404/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5439 - val_loss: 9.4979\n",
      "Epoch 405/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.2981 - val_loss: 6.5896\n",
      "Epoch 406/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.2774 - val_loss: 6.2669\n",
      "Epoch 407/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.3533 - val_loss: 9.6155\n",
      "Epoch 408/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.1490 - val_loss: 7.0949\n",
      "Epoch 409/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.0104 - val_loss: 6.2770\n",
      "Epoch 410/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.7896 - val_loss: 6.1284\n",
      "Epoch 411/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.1242 - val_loss: 6.2423\n",
      "Epoch 412/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0560 - val_loss: 6.1838\n",
      "Epoch 413/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.2876 - val_loss: 7.5304\n",
      "Epoch 414/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.5675 - val_loss: 6.3419\n",
      "Epoch 415/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0165 - val_loss: 5.7048\n",
      "Epoch 416/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.4310 - val_loss: 7.0174\n",
      "Epoch 417/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.0474 - val_loss: 6.3104\n",
      "Epoch 418/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1084 - val_loss: 6.1002\n",
      "Epoch 419/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.1430 - val_loss: 7.6372\n",
      "Epoch 420/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.6955 - val_loss: 7.3221\n",
      "Epoch 421/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.3177 - val_loss: 6.1204\n",
      "Epoch 422/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.3134 - val_loss: 6.4171\n",
      "Epoch 423/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.9121 - val_loss: 5.9858\n",
      "Epoch 424/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0807 - val_loss: 7.4198\n",
      "Epoch 425/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.1229 - val_loss: 6.2859\n",
      "Epoch 426/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.2147 - val_loss: 7.2387\n",
      "Epoch 427/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1672 - val_loss: 8.2800\n",
      "Epoch 428/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.1163 - val_loss: 6.1851\n",
      "Epoch 429/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.6095 - val_loss: 7.6278\n",
      "Epoch 430/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.3788 - val_loss: 6.8650\n",
      "Epoch 431/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3852 - val_loss: 6.1079\n",
      "Epoch 432/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.9695 - val_loss: 5.9959\n",
      "Epoch 433/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.1269 - val_loss: 8.0973\n",
      "Epoch 434/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.9199 - val_loss: 6.3013\n",
      "Epoch 435/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8397 - val_loss: 6.2479\n",
      "Epoch 436/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.9191 - val_loss: 6.8277\n",
      "Epoch 437/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1913 - val_loss: 6.2560\n",
      "Epoch 438/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.5522 - val_loss: 7.8024\n",
      "Epoch 439/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.4796 - val_loss: 7.0306\n",
      "Epoch 440/1000\n",
      "1953/1953 [==============================] - 0s 115us/step - loss: 5.3315 - val_loss: 5.8847\n",
      "Epoch 441/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.1567 - val_loss: 6.3537\n",
      "Epoch 442/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.0346 - val_loss: 6.5256\n",
      "Epoch 443/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.9406 - val_loss: 6.4685\n",
      "Epoch 444/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8584 - val_loss: 5.8802\n",
      "Epoch 445/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0520 - val_loss: 5.8603\n",
      "Epoch 446/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0721 - val_loss: 8.1946\n",
      "Epoch 447/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0903 - val_loss: 6.1453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.9954 - val_loss: 6.4421\n",
      "Epoch 449/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 5.1113 - val_loss: 5.5957\n",
      "Epoch 450/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 4.9068 - val_loss: 7.2981\n",
      "Epoch 451/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8759 - val_loss: 6.5746\n",
      "Epoch 452/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.0883 - val_loss: 6.0583\n",
      "Epoch 453/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.0533 - val_loss: 5.9176\n",
      "Epoch 454/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.8464 - val_loss: 7.1443\n",
      "Epoch 455/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0214 - val_loss: 6.1237\n",
      "Epoch 456/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.8607 - val_loss: 6.3308\n",
      "Epoch 457/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8946 - val_loss: 6.2532\n",
      "Epoch 458/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.3512 - val_loss: 8.9054\n",
      "Epoch 459/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.6515 - val_loss: 7.7671\n",
      "Epoch 460/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 5.3383 - val_loss: 5.9044\n",
      "Epoch 461/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.9542 - val_loss: 7.1105\n",
      "Epoch 462/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.5204 - val_loss: 6.3572\n",
      "Epoch 463/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 5.2885 - val_loss: 6.1297\n",
      "Epoch 464/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0085 - val_loss: 6.7359\n",
      "Epoch 465/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.9768 - val_loss: 6.4131\n",
      "Epoch 466/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.2393 - val_loss: 7.2546\n",
      "Epoch 467/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.9262 - val_loss: 6.9134\n",
      "Epoch 468/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.1284 - val_loss: 5.9649\n",
      "Epoch 469/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.8927 - val_loss: 8.0412\n",
      "Epoch 470/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.0983 - val_loss: 5.9711\n",
      "Epoch 471/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8277 - val_loss: 6.5089\n",
      "Epoch 472/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.1881 - val_loss: 5.8345\n",
      "Epoch 473/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0525 - val_loss: 5.8292\n",
      "Epoch 474/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 5.0413 - val_loss: 6.6797\n",
      "Epoch 475/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3908 - val_loss: 6.1379\n",
      "Epoch 476/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0563 - val_loss: 6.2144\n",
      "Epoch 477/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.9747 - val_loss: 6.3580\n",
      "Epoch 478/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.1724 - val_loss: 8.7416\n",
      "Epoch 479/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8799 - val_loss: 6.6966\n",
      "Epoch 480/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.6549 - val_loss: 5.9264\n",
      "Epoch 481/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.6380 - val_loss: 6.6144\n",
      "Epoch 482/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8752 - val_loss: 5.8745\n",
      "Epoch 483/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.2848 - val_loss: 5.6103\n",
      "Epoch 484/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6587 - val_loss: 5.7832\n",
      "Epoch 485/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8470 - val_loss: 6.4225\n",
      "Epoch 486/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.2290 - val_loss: 6.2600\n",
      "Epoch 487/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.9069 - val_loss: 6.3207\n",
      "Epoch 488/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.9319 - val_loss: 5.7606\n",
      "Epoch 489/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8323 - val_loss: 8.9308\n",
      "Epoch 490/1000\n",
      "1953/1953 [==============================] - 0s 117us/step - loss: 5.2351 - val_loss: 5.7542\n",
      "Epoch 491/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.9791 - val_loss: 5.6934\n",
      "Epoch 492/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.9623 - val_loss: 6.6538\n",
      "Epoch 493/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.3494 - val_loss: 6.5626\n",
      "Epoch 494/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6365 - val_loss: 6.6917\n",
      "Epoch 495/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8583 - val_loss: 6.7273\n",
      "Epoch 496/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0051 - val_loss: 6.5204\n",
      "Epoch 497/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8088 - val_loss: 5.9580\n",
      "Epoch 498/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8317 - val_loss: 6.1177\n",
      "Epoch 499/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.4674 - val_loss: 5.7705\n",
      "Epoch 500/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.7769 - val_loss: 6.5253\n",
      "Epoch 501/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.3116 - val_loss: 6.2376\n",
      "Epoch 502/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8139 - val_loss: 7.2839\n",
      "Epoch 503/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.7880 - val_loss: 6.6189\n",
      "Epoch 504/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5306 - val_loss: 6.8318\n",
      "Epoch 505/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8976 - val_loss: 10.3498\n",
      "Epoch 506/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.3396 - val_loss: 6.1582\n",
      "Epoch 507/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5809 - val_loss: 6.0104\n",
      "Epoch 508/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.4726 - val_loss: 6.2457\n",
      "Epoch 509/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8435 - val_loss: 5.8972\n",
      "Epoch 510/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6599 - val_loss: 6.5097\n",
      "Epoch 511/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8444 - val_loss: 5.8640\n",
      "Epoch 512/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.7725 - val_loss: 5.8464\n",
      "Epoch 513/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6709 - val_loss: 6.3550\n",
      "Epoch 514/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5580 - val_loss: 6.5595\n",
      "Epoch 515/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.9345 - val_loss: 6.4598\n",
      "Epoch 516/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8133 - val_loss: 6.0942\n",
      "Epoch 517/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8988 - val_loss: 5.9300\n",
      "Epoch 518/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0443 - val_loss: 6.5079\n",
      "Epoch 519/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8950 - val_loss: 6.7227\n",
      "Epoch 520/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.1981 - val_loss: 6.8218\n",
      "Epoch 521/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.7318 - val_loss: 6.2995\n",
      "Epoch 522/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5857 - val_loss: 6.9166\n",
      "Epoch 523/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.7129 - val_loss: 6.3105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.6029 - val_loss: 6.1397\n",
      "Epoch 525/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 4.9305 - val_loss: 6.1379\n",
      "Epoch 526/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 5.1974 - val_loss: 6.3389\n",
      "Epoch 527/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.0460 - val_loss: 7.1396\n",
      "Epoch 528/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.0940 - val_loss: 6.2884\n",
      "Epoch 529/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.8038 - val_loss: 5.7648\n",
      "Epoch 530/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.8603 - val_loss: 6.1467\n",
      "Epoch 531/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 4.6542 - val_loss: 5.8534\n",
      "Epoch 532/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.8504 - val_loss: 5.8250\n",
      "Epoch 533/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.6128 - val_loss: 7.1523\n",
      "Epoch 534/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5514 - val_loss: 5.9888\n",
      "Epoch 535/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5496 - val_loss: 5.9016\n",
      "Epoch 536/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8588 - val_loss: 5.9701\n",
      "Epoch 537/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6988 - val_loss: 6.1804\n",
      "Epoch 538/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.8485 - val_loss: 6.8285\n",
      "Epoch 539/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.8877 - val_loss: 5.9882\n",
      "Epoch 540/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.7192 - val_loss: 6.1519\n",
      "Epoch 541/1000\n",
      "1953/1953 [==============================] - 0s 119us/step - loss: 4.9403 - val_loss: 6.5681\n",
      "Epoch 542/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.5541 - val_loss: 5.8208\n",
      "Epoch 543/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.6948 - val_loss: 6.4725\n",
      "Epoch 544/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.2600 - val_loss: 6.2977\n",
      "Epoch 545/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0564 - val_loss: 6.6106\n",
      "Epoch 546/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1474 - val_loss: 5.9350\n",
      "Epoch 547/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.6474 - val_loss: 6.7562\n",
      "Epoch 548/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.6476 - val_loss: 6.1810\n",
      "Epoch 549/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.0797 - val_loss: 6.9311\n",
      "Epoch 550/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5549 - val_loss: 5.8115\n",
      "Epoch 551/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5862 - val_loss: 7.1641\n",
      "Epoch 552/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.7137 - val_loss: 5.8413\n",
      "Epoch 553/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 5.3174 - val_loss: 5.8571\n",
      "Epoch 554/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.5068 - val_loss: 7.9070\n",
      "Epoch 555/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.6713 - val_loss: 5.9524\n",
      "Epoch 556/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5557 - val_loss: 6.0365\n",
      "Epoch 557/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0518 - val_loss: 5.7440\n",
      "Epoch 558/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.6292 - val_loss: 6.3649\n",
      "Epoch 559/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.6395 - val_loss: 5.9232\n",
      "Epoch 560/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.8704 - val_loss: 6.0297\n",
      "Epoch 561/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8882 - val_loss: 6.4487\n",
      "Epoch 562/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5676 - val_loss: 6.0775\n",
      "Epoch 563/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5535 - val_loss: 7.1686\n",
      "Epoch 564/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.6869 - val_loss: 7.2749\n",
      "Epoch 565/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.1124 - val_loss: 6.4169\n",
      "Epoch 566/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.9517 - val_loss: 5.7761\n",
      "Epoch 567/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5114 - val_loss: 5.8917\n",
      "Epoch 568/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5099 - val_loss: 6.0871\n",
      "Epoch 569/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5355 - val_loss: 7.7366\n",
      "Epoch 570/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1533 - val_loss: 5.8706\n",
      "Epoch 571/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.4980 - val_loss: 5.4180\n",
      "Epoch 572/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.9079 - val_loss: 5.6927\n",
      "Epoch 573/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.9835 - val_loss: 7.3007\n",
      "Epoch 574/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8646 - val_loss: 6.9258\n",
      "Epoch 575/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.6519 - val_loss: 5.8934\n",
      "Epoch 576/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.4668 - val_loss: 6.2436\n",
      "Epoch 577/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4279 - val_loss: 6.6470\n",
      "Epoch 578/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8500 - val_loss: 6.0490\n",
      "Epoch 579/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.9186 - val_loss: 5.8198\n",
      "Epoch 580/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.9349 - val_loss: 7.1983\n",
      "Epoch 581/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.7923 - val_loss: 6.7679\n",
      "Epoch 582/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5556 - val_loss: 7.2174\n",
      "Epoch 583/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.7063 - val_loss: 5.8491\n",
      "Epoch 584/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5724 - val_loss: 5.6614\n",
      "Epoch 585/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5247 - val_loss: 5.6093\n",
      "Epoch 586/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5241 - val_loss: 6.0315\n",
      "Epoch 587/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 5.2591 - val_loss: 7.9943\n",
      "Epoch 588/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.0425 - val_loss: 5.7197\n",
      "Epoch 589/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4485 - val_loss: 6.3572\n",
      "Epoch 590/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.8308 - val_loss: 5.7026\n",
      "Epoch 591/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.7012 - val_loss: 5.8834\n",
      "Epoch 592/1000\n",
      "1953/1953 [==============================] - 0s 114us/step - loss: 4.6486 - val_loss: 7.2083\n",
      "Epoch 593/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5078 - val_loss: 5.9440\n",
      "Epoch 594/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4375 - val_loss: 7.1231\n",
      "Epoch 595/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.3849 - val_loss: 6.1604\n",
      "Epoch 596/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.3842 - val_loss: 5.7062\n",
      "Epoch 597/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8230 - val_loss: 6.1705\n",
      "Epoch 598/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 5.1133 - val_loss: 6.0390\n",
      "Epoch 599/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6583 - val_loss: 5.6061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.4076 - val_loss: 6.0182\n",
      "Epoch 601/1000\n",
      "1953/1953 [==============================] - 0s 98us/step - loss: 4.7898 - val_loss: 5.8061\n",
      "Epoch 602/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.4010 - val_loss: 6.3485\n",
      "Epoch 603/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 5.0692 - val_loss: 6.0973\n",
      "Epoch 604/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.5671 - val_loss: 6.2107\n",
      "Epoch 605/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5883 - val_loss: 6.5846\n",
      "Epoch 606/1000\n",
      "1953/1953 [==============================] - 0s 99us/step - loss: 4.6701 - val_loss: 7.2303\n",
      "Epoch 607/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.3430 - val_loss: 5.9931\n",
      "Epoch 608/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.3718 - val_loss: 5.6397\n",
      "Epoch 609/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.4532 - val_loss: 5.8952\n",
      "Epoch 610/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.8454 - val_loss: 6.9306\n",
      "Epoch 611/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.5306 - val_loss: 6.1973\n",
      "Epoch 612/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.4406 - val_loss: 6.2460\n",
      "Epoch 613/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 4.3405 - val_loss: 5.4900\n",
      "Epoch 614/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.3603 - val_loss: 5.9125\n",
      "Epoch 615/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.4297 - val_loss: 9.5366\n",
      "Epoch 616/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.5257 - val_loss: 6.4882\n",
      "Epoch 617/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4283 - val_loss: 7.1732\n",
      "Epoch 618/1000\n",
      "1953/1953 [==============================] - 0s 100us/step - loss: 5.0479 - val_loss: 5.7530\n",
      "Epoch 619/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.7470 - val_loss: 7.2660\n",
      "Epoch 620/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.6301 - val_loss: 5.7856\n",
      "Epoch 621/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.3041 - val_loss: 5.8639\n",
      "Epoch 622/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.3432 - val_loss: 6.5573\n",
      "Epoch 623/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.8763 - val_loss: 5.7607\n",
      "Epoch 624/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 5.0743 - val_loss: 6.4324\n",
      "Epoch 625/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 4.4986 - val_loss: 5.5843\n",
      "Epoch 626/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.3019 - val_loss: 5.6392\n",
      "Epoch 627/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5281 - val_loss: 5.7185\n",
      "Epoch 628/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.4023 - val_loss: 5.8430\n",
      "Epoch 629/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.3904 - val_loss: 5.7375\n",
      "Epoch 630/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.3073 - val_loss: 7.2142\n",
      "Epoch 631/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4981 - val_loss: 6.8202\n",
      "Epoch 632/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5719 - val_loss: 6.0132\n",
      "Epoch 633/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.4793 - val_loss: 6.3165\n",
      "Epoch 634/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4757 - val_loss: 5.6687\n",
      "Epoch 635/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.4760 - val_loss: 6.0001\n",
      "Epoch 636/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.5990 - val_loss: 5.4674\n",
      "Epoch 637/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.2429 - val_loss: 6.5832\n",
      "Epoch 638/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5564 - val_loss: 6.4037\n",
      "Epoch 639/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5477 - val_loss: 6.3272\n",
      "Epoch 640/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.3577 - val_loss: 7.0459\n",
      "Epoch 641/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.3920 - val_loss: 5.6950\n",
      "Epoch 642/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.4891 - val_loss: 6.7838\n",
      "Epoch 643/1000\n",
      "1953/1953 [==============================] - 0s 119us/step - loss: 4.6434 - val_loss: 5.7324\n",
      "Epoch 644/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.3001 - val_loss: 5.6596\n",
      "Epoch 645/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.5779 - val_loss: 6.0032\n",
      "Epoch 646/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.4865 - val_loss: 6.4482\n",
      "Epoch 647/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.4363 - val_loss: 6.5012\n",
      "Epoch 648/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.3528 - val_loss: 5.9052\n",
      "Epoch 649/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5399 - val_loss: 5.9718\n",
      "Epoch 650/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.2833 - val_loss: 6.6807\n",
      "Epoch 651/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.4186 - val_loss: 6.2201\n",
      "Epoch 652/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4821 - val_loss: 6.5737\n",
      "Epoch 653/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.4551 - val_loss: 5.8974\n",
      "Epoch 654/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.3125 - val_loss: 7.0683\n",
      "Epoch 655/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.4669 - val_loss: 6.2300\n",
      "Epoch 656/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.6851 - val_loss: 6.4428\n",
      "Epoch 657/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.2209 - val_loss: 6.3282\n",
      "Epoch 658/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2912 - val_loss: 5.9598\n",
      "Epoch 659/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.3906 - val_loss: 6.1422\n",
      "Epoch 660/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 5.0794 - val_loss: 6.6095\n",
      "Epoch 661/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.3489 - val_loss: 6.5551\n",
      "Epoch 662/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.3144 - val_loss: 6.8401\n",
      "Epoch 663/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.2728 - val_loss: 7.1007\n",
      "Epoch 664/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2884 - val_loss: 6.9582\n",
      "Epoch 665/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.6596 - val_loss: 6.0312\n",
      "Epoch 666/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.4582 - val_loss: 5.7786\n",
      "Epoch 667/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.8647 - val_loss: 6.2569\n",
      "Epoch 668/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5504 - val_loss: 6.5598\n",
      "Epoch 669/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5415 - val_loss: 6.0208\n",
      "Epoch 670/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2557 - val_loss: 7.4662\n",
      "Epoch 671/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.4405 - val_loss: 6.1693\n",
      "Epoch 672/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.1273 - val_loss: 6.6049\n",
      "Epoch 673/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5357 - val_loss: 6.0583\n",
      "Epoch 674/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.7932 - val_loss: 7.4883\n",
      "Epoch 675/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5739 - val_loss: 5.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 676/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2860 - val_loss: 6.7654\n",
      "Epoch 677/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.8029 - val_loss: 6.1866\n",
      "Epoch 678/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.7491 - val_loss: 6.9876\n",
      "Epoch 679/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2393 - val_loss: 6.0340\n",
      "Epoch 680/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.1290 - val_loss: 6.0781\n",
      "Epoch 681/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.2908 - val_loss: 6.2032\n",
      "Epoch 682/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.2170 - val_loss: 6.5827\n",
      "Epoch 683/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.4275 - val_loss: 5.9341\n",
      "Epoch 684/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.3093 - val_loss: 6.4142\n",
      "Epoch 685/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.3276 - val_loss: 6.7255\n",
      "Epoch 686/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.0246 - val_loss: 6.0314\n",
      "Epoch 687/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.3718 - val_loss: 6.0572\n",
      "Epoch 688/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2282 - val_loss: 5.7151\n",
      "Epoch 689/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.4461 - val_loss: 6.7517\n",
      "Epoch 690/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.1114 - val_loss: 5.7147\n",
      "Epoch 691/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.5080 - val_loss: 5.9421\n",
      "Epoch 692/1000\n",
      "1953/1953 [==============================] - 0s 113us/step - loss: 4.5885 - val_loss: 8.8573\n",
      "Epoch 693/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 4.5168 - val_loss: 6.3007\n",
      "Epoch 694/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.1713 - val_loss: 6.2123\n",
      "Epoch 695/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.2845 - val_loss: 6.3255\n",
      "Epoch 696/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.2602 - val_loss: 6.2392\n",
      "Epoch 697/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.7137 - val_loss: 5.8834\n",
      "Epoch 698/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.3606 - val_loss: 8.2469\n",
      "Epoch 699/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.8186 - val_loss: 5.9463\n",
      "Epoch 700/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.3551 - val_loss: 7.5758\n",
      "Epoch 701/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.1713 - val_loss: 5.7866\n",
      "Epoch 702/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.2150 - val_loss: 5.8809\n",
      "Epoch 703/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.3291 - val_loss: 6.2995\n",
      "Epoch 704/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.4611 - val_loss: 5.7902\n",
      "Epoch 705/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.4029 - val_loss: 6.7951\n",
      "Epoch 706/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2294 - val_loss: 5.9121\n",
      "Epoch 707/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.3261 - val_loss: 5.7732\n",
      "Epoch 708/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.1956 - val_loss: 6.4721\n",
      "Epoch 709/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.3312 - val_loss: 6.4144\n",
      "Epoch 710/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.2674 - val_loss: 6.5511\n",
      "Epoch 711/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.1097 - val_loss: 6.0394\n",
      "Epoch 712/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1465 - val_loss: 6.1044\n",
      "Epoch 713/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.2514 - val_loss: 6.6145\n",
      "Epoch 714/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.3541 - val_loss: 7.0228\n",
      "Epoch 715/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.6783 - val_loss: 6.8140\n",
      "Epoch 716/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.0729 - val_loss: 6.8332\n",
      "Epoch 717/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.7368 - val_loss: 7.5213\n",
      "Epoch 718/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.1407 - val_loss: 6.0465\n",
      "Epoch 719/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.3257 - val_loss: 5.9991\n",
      "Epoch 720/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.2307 - val_loss: 5.5479\n",
      "Epoch 721/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.2464 - val_loss: 6.4290\n",
      "Epoch 722/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 5.3649 - val_loss: 5.9609\n",
      "Epoch 723/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.3226 - val_loss: 6.7283\n",
      "Epoch 724/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.3951 - val_loss: 5.9950\n",
      "Epoch 725/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.1147 - val_loss: 6.9801\n",
      "Epoch 726/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0822 - val_loss: 5.7336\n",
      "Epoch 727/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2296 - val_loss: 6.1565\n",
      "Epoch 728/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.9907 - val_loss: 5.8912\n",
      "Epoch 729/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2629 - val_loss: 6.1022\n",
      "Epoch 730/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.1670 - val_loss: 5.8688\n",
      "Epoch 731/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0705 - val_loss: 6.3691\n",
      "Epoch 732/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.1639 - val_loss: 6.3201\n",
      "Epoch 733/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.1255 - val_loss: 7.0703\n",
      "Epoch 734/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.0350 - val_loss: 6.0148\n",
      "Epoch 735/1000\n",
      "1953/1953 [==============================] - 0s 101us/step - loss: 4.3180 - val_loss: 7.3040\n",
      "Epoch 736/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1958 - val_loss: 5.9805\n",
      "Epoch 737/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.2253 - val_loss: 7.3136\n",
      "Epoch 738/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.0773 - val_loss: 5.7751\n",
      "Epoch 739/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.2334 - val_loss: 6.7637\n",
      "Epoch 740/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.1085 - val_loss: 6.0995\n",
      "Epoch 741/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.4679 - val_loss: 6.3443\n",
      "Epoch 742/1000\n",
      "1953/1953 [==============================] - 0s 125us/step - loss: 4.2309 - val_loss: 5.9314\n",
      "Epoch 743/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.9712 - val_loss: 5.9327\n",
      "Epoch 744/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.2813 - val_loss: 6.7207\n",
      "Epoch 745/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1733 - val_loss: 5.9615\n",
      "Epoch 746/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5323 - val_loss: 6.5843\n",
      "Epoch 747/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.4101 - val_loss: 6.0043\n",
      "Epoch 748/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.6543 - val_loss: 6.2110\n",
      "Epoch 749/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.2049 - val_loss: 6.4537\n",
      "Epoch 750/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.2103 - val_loss: 6.5086\n",
      "Epoch 751/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.8712 - val_loss: 6.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 752/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5838 - val_loss: 6.2448\n",
      "Epoch 753/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.6257 - val_loss: 6.7395\n",
      "Epoch 754/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2464 - val_loss: 7.1347\n",
      "Epoch 755/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.9221 - val_loss: 6.1001\n",
      "Epoch 756/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5458 - val_loss: 7.6018\n",
      "Epoch 757/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.5326 - val_loss: 6.1557\n",
      "Epoch 758/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.9208 - val_loss: 5.8484\n",
      "Epoch 759/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2775 - val_loss: 5.8289\n",
      "Epoch 760/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.1516 - val_loss: 6.3488\n",
      "Epoch 761/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.1049 - val_loss: 5.8100\n",
      "Epoch 762/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.1944 - val_loss: 5.7753\n",
      "Epoch 763/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.1823 - val_loss: 5.9894\n",
      "Epoch 764/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2959 - val_loss: 9.0649\n",
      "Epoch 765/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.1400 - val_loss: 6.8634\n",
      "Epoch 766/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2249 - val_loss: 6.0065\n",
      "Epoch 767/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.5111 - val_loss: 6.3556\n",
      "Epoch 768/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.9214 - val_loss: 5.9710\n",
      "Epoch 769/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.5461 - val_loss: 6.8646\n",
      "Epoch 770/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 4.3297 - val_loss: 6.1394\n",
      "Epoch 771/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.5416 - val_loss: 6.0176\n",
      "Epoch 772/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9758 - val_loss: 5.9214\n",
      "Epoch 773/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2020 - val_loss: 6.0631\n",
      "Epoch 774/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2287 - val_loss: 7.1225\n",
      "Epoch 775/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.4247 - val_loss: 6.2300\n",
      "Epoch 776/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.8837 - val_loss: 6.6413\n",
      "Epoch 777/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9484 - val_loss: 6.5860\n",
      "Epoch 778/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 4.2407 - val_loss: 5.6950\n",
      "Epoch 779/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.9433 - val_loss: 6.3265\n",
      "Epoch 780/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 4.4392 - val_loss: 5.9783\n",
      "Epoch 781/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.2229 - val_loss: 5.9671\n",
      "Epoch 782/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.8652 - val_loss: 6.1559\n",
      "Epoch 783/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 4.4497 - val_loss: 6.6727\n",
      "Epoch 784/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1168 - val_loss: 7.6965\n",
      "Epoch 785/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.1138 - val_loss: 5.6740\n",
      "Epoch 786/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.0764 - val_loss: 5.7533\n",
      "Epoch 787/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9116 - val_loss: 6.6532\n",
      "Epoch 788/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.0119 - val_loss: 6.4937\n",
      "Epoch 789/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1514 - val_loss: 6.0098\n",
      "Epoch 790/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.0420 - val_loss: 5.7980\n",
      "Epoch 791/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8369 - val_loss: 6.2129\n",
      "Epoch 792/1000\n",
      "1953/1953 [==============================] - 0s 114us/step - loss: 3.7370 - val_loss: 6.5133\n",
      "Epoch 793/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.1097 - val_loss: 6.9070\n",
      "Epoch 794/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.0407 - val_loss: 6.5448\n",
      "Epoch 795/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 4.1463 - val_loss: 6.0630\n",
      "Epoch 796/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 4.0164 - val_loss: 7.8554\n",
      "Epoch 797/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.2309 - val_loss: 6.1782\n",
      "Epoch 798/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.1204 - val_loss: 6.0203\n",
      "Epoch 799/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.3525 - val_loss: 5.7696\n",
      "Epoch 800/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.0110 - val_loss: 6.2726\n",
      "Epoch 801/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 4.0895 - val_loss: 5.9607\n",
      "Epoch 802/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 3.8778 - val_loss: 5.8665\n",
      "Epoch 803/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.9061 - val_loss: 6.1193\n",
      "Epoch 804/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.9894 - val_loss: 6.0328\n",
      "Epoch 805/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.9104 - val_loss: 5.9125\n",
      "Epoch 806/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.2440 - val_loss: 6.7832\n",
      "Epoch 807/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.8431 - val_loss: 6.0814\n",
      "Epoch 808/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0943 - val_loss: 7.1419\n",
      "Epoch 809/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8951 - val_loss: 7.5140\n",
      "Epoch 810/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9681 - val_loss: 5.9139\n",
      "Epoch 811/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9769 - val_loss: 6.0657\n",
      "Epoch 812/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9608 - val_loss: 7.8053\n",
      "Epoch 813/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.8786 - val_loss: 5.4929\n",
      "Epoch 814/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 3.9735 - val_loss: 5.8849\n",
      "Epoch 815/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1085 - val_loss: 6.4563\n",
      "Epoch 816/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.0401 - val_loss: 6.3337\n",
      "Epoch 817/1000\n",
      "1953/1953 [==============================] - 0s 112us/step - loss: 3.9505 - val_loss: 6.8695\n",
      "Epoch 818/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.2265 - val_loss: 6.6621\n",
      "Epoch 819/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.9354 - val_loss: 6.0005\n",
      "Epoch 820/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8778 - val_loss: 5.8402\n",
      "Epoch 821/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.9238 - val_loss: 5.6772\n",
      "Epoch 822/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 4.1684 - val_loss: 6.7448\n",
      "Epoch 823/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.0201 - val_loss: 5.7828\n",
      "Epoch 824/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.9685 - val_loss: 5.9898\n",
      "Epoch 825/1000\n",
      "1953/1953 [==============================] - 0s 112us/step - loss: 4.0534 - val_loss: 5.9346\n",
      "Epoch 826/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.0573 - val_loss: 6.8040\n",
      "Epoch 827/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9619 - val_loss: 5.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.8971 - val_loss: 6.1906\n",
      "Epoch 829/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.0245 - val_loss: 6.0644\n",
      "Epoch 830/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0745 - val_loss: 5.8655\n",
      "Epoch 831/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2181 - val_loss: 5.6975\n",
      "Epoch 832/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.9417 - val_loss: 5.9417\n",
      "Epoch 833/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.8489 - val_loss: 5.9136\n",
      "Epoch 834/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2376 - val_loss: 5.7190\n",
      "Epoch 835/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.4106 - val_loss: 5.6401\n",
      "Epoch 836/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.8056 - val_loss: 5.8719\n",
      "Epoch 837/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.9390 - val_loss: 6.3567\n",
      "Epoch 838/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.1019 - val_loss: 5.7256\n",
      "Epoch 839/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.7978 - val_loss: 6.9904\n",
      "Epoch 840/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9764 - val_loss: 5.9853\n",
      "Epoch 841/1000\n",
      "1953/1953 [==============================] - 0s 121us/step - loss: 3.9308 - val_loss: 6.6281\n",
      "Epoch 842/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 4.0718 - val_loss: 6.1753\n",
      "Epoch 843/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7615 - val_loss: 5.6616\n",
      "Epoch 844/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8720 - val_loss: 6.3564\n",
      "Epoch 845/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.2641 - val_loss: 6.5009\n",
      "Epoch 846/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.0788 - val_loss: 6.6222\n",
      "Epoch 847/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8235 - val_loss: 5.8179\n",
      "Epoch 848/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.8394 - val_loss: 5.6360\n",
      "Epoch 849/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8985 - val_loss: 7.2738\n",
      "Epoch 850/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 4.0431 - val_loss: 6.2329\n",
      "Epoch 851/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.0454 - val_loss: 5.6534\n",
      "Epoch 852/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 3.6980 - val_loss: 7.1536\n",
      "Epoch 853/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9759 - val_loss: 5.7992\n",
      "Epoch 854/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.8018 - val_loss: 6.9352\n",
      "Epoch 855/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0849 - val_loss: 6.0022\n",
      "Epoch 856/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7727 - val_loss: 6.0138\n",
      "Epoch 857/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7902 - val_loss: 5.8678\n",
      "Epoch 858/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.6572 - val_loss: 6.0198\n",
      "Epoch 859/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0416 - val_loss: 5.6634\n",
      "Epoch 860/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9991 - val_loss: 5.9537\n",
      "Epoch 861/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.8943 - val_loss: 9.2684\n",
      "Epoch 862/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.2609 - val_loss: 6.5956\n",
      "Epoch 863/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 4.2503 - val_loss: 6.2721\n",
      "Epoch 864/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9555 - val_loss: 7.4477\n",
      "Epoch 865/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7536 - val_loss: 6.1274\n",
      "Epoch 866/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7391 - val_loss: 6.0581\n",
      "Epoch 867/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8167 - val_loss: 6.1491\n",
      "Epoch 868/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6763 - val_loss: 5.6904\n",
      "Epoch 869/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.7164 - val_loss: 6.4296\n",
      "Epoch 870/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7510 - val_loss: 5.6686\n",
      "Epoch 871/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7411 - val_loss: 6.1210\n",
      "Epoch 872/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8377 - val_loss: 6.9228\n",
      "Epoch 873/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8808 - val_loss: 7.9248\n",
      "Epoch 874/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7932 - val_loss: 6.2040\n",
      "Epoch 875/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7987 - val_loss: 6.0273\n",
      "Epoch 876/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7690 - val_loss: 6.1321\n",
      "Epoch 877/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.9439 - val_loss: 6.3524\n",
      "Epoch 878/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.7780 - val_loss: 6.2421\n",
      "Epoch 879/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 3.6439 - val_loss: 5.7881\n",
      "Epoch 880/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7789 - val_loss: 6.3501\n",
      "Epoch 881/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.7114 - val_loss: 5.9278\n",
      "Epoch 882/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8390 - val_loss: 5.6644\n",
      "Epoch 883/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6067 - val_loss: 6.4080\n",
      "Epoch 884/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.7196 - val_loss: 5.8891\n",
      "Epoch 885/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.8053 - val_loss: 6.4117\n",
      "Epoch 886/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8122 - val_loss: 6.1983\n",
      "Epoch 887/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8798 - val_loss: 5.7278\n",
      "Epoch 888/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 3.5975 - val_loss: 5.8804\n",
      "Epoch 889/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.9073 - val_loss: 6.2270\n",
      "Epoch 890/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 3.6653 - val_loss: 6.4038\n",
      "Epoch 891/1000\n",
      "1953/1953 [==============================] - 0s 116us/step - loss: 3.9819 - val_loss: 6.3936\n",
      "Epoch 892/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8507 - val_loss: 6.8414\n",
      "Epoch 893/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7734 - val_loss: 6.4407\n",
      "Epoch 894/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7787 - val_loss: 6.8046\n",
      "Epoch 895/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.9131 - val_loss: 5.9448\n",
      "Epoch 896/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5964 - val_loss: 5.7230\n",
      "Epoch 897/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7734 - val_loss: 6.3922\n",
      "Epoch 898/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.5401 - val_loss: 5.9996\n",
      "Epoch 899/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.7889 - val_loss: 5.7903\n",
      "Epoch 900/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.7452 - val_loss: 6.0277\n",
      "Epoch 901/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.5721 - val_loss: 5.9704\n",
      "Epoch 902/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.4689 - val_loss: 6.2000\n",
      "Epoch 903/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 4.0570 - val_loss: 6.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 904/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7575 - val_loss: 6.2539\n",
      "Epoch 905/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9648 - val_loss: 7.1091\n",
      "Epoch 906/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.6558 - val_loss: 6.2925\n",
      "Epoch 907/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8574 - val_loss: 6.4024\n",
      "Epoch 908/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.5978 - val_loss: 5.9500\n",
      "Epoch 909/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.6692 - val_loss: 7.3047\n",
      "Epoch 910/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.5409 - val_loss: 6.2681\n",
      "Epoch 911/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.7723 - val_loss: 6.3505\n",
      "Epoch 912/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.8484 - val_loss: 6.7342\n",
      "Epoch 913/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.6832 - val_loss: 6.4354\n",
      "Epoch 914/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.7943 - val_loss: 6.0561\n",
      "Epoch 915/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5562 - val_loss: 5.6495\n",
      "Epoch 916/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.5774 - val_loss: 7.5803\n",
      "Epoch 917/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.6365 - val_loss: 7.2964\n",
      "Epoch 918/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.6167 - val_loss: 6.1387\n",
      "Epoch 919/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9745 - val_loss: 6.9248\n",
      "Epoch 920/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 3.6141 - val_loss: 5.9562\n",
      "Epoch 921/1000\n",
      "1953/1953 [==============================] - 0s 131us/step - loss: 3.5467 - val_loss: 7.0197\n",
      "Epoch 922/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 3.6463 - val_loss: 5.8866\n",
      "Epoch 923/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.5338 - val_loss: 6.2991\n",
      "Epoch 924/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7219 - val_loss: 5.8979\n",
      "Epoch 925/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8015 - val_loss: 6.3690\n",
      "Epoch 926/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5795 - val_loss: 5.8744\n",
      "Epoch 927/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6783 - val_loss: 5.5903\n",
      "Epoch 928/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 3.5659 - val_loss: 6.3658\n",
      "Epoch 929/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 4.0342 - val_loss: 7.1805\n",
      "Epoch 930/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.4991 - val_loss: 6.6413\n",
      "Epoch 931/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.9788 - val_loss: 7.6527\n",
      "Epoch 932/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5883 - val_loss: 6.2675\n",
      "Epoch 933/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.9385 - val_loss: 5.7564\n",
      "Epoch 934/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5509 - val_loss: 6.8851\n",
      "Epoch 935/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8984 - val_loss: 5.8397\n",
      "Epoch 936/1000\n",
      "1953/1953 [==============================] - 0s 111us/step - loss: 3.9742 - val_loss: 5.8165\n",
      "Epoch 937/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.7647 - val_loss: 6.4282\n",
      "Epoch 938/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.5629 - val_loss: 5.9450\n",
      "Epoch 939/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6241 - val_loss: 6.5498\n",
      "Epoch 940/1000\n",
      "1953/1953 [==============================] - 0s 124us/step - loss: 3.6157 - val_loss: 5.8951\n",
      "Epoch 941/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.8544 - val_loss: 5.9098\n",
      "Epoch 942/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.4864 - val_loss: 6.2009\n",
      "Epoch 943/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8811 - val_loss: 8.0595\n",
      "Epoch 944/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7963 - val_loss: 6.2037\n",
      "Epoch 945/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.7015 - val_loss: 6.0490\n",
      "Epoch 946/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.6003 - val_loss: 6.1043\n",
      "Epoch 947/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7579 - val_loss: 5.7512\n",
      "Epoch 948/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5110 - val_loss: 6.1935\n",
      "Epoch 949/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.2711 - val_loss: 5.5344\n",
      "Epoch 950/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.4834 - val_loss: 6.3324\n",
      "Epoch 951/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.4742 - val_loss: 6.2950\n",
      "Epoch 952/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5326 - val_loss: 7.9660\n",
      "Epoch 953/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8095 - val_loss: 6.4738\n",
      "Epoch 954/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6867 - val_loss: 6.2758\n",
      "Epoch 955/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.4334 - val_loss: 6.0527\n",
      "Epoch 956/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5277 - val_loss: 6.1494\n",
      "Epoch 957/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.8641 - val_loss: 6.8311\n",
      "Epoch 958/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5444 - val_loss: 6.0310\n",
      "Epoch 959/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6948 - val_loss: 5.9574\n",
      "Epoch 960/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.8520 - val_loss: 5.6862\n",
      "Epoch 961/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.6887 - val_loss: 6.3303\n",
      "Epoch 962/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.4683 - val_loss: 6.0324\n",
      "Epoch 963/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.4492 - val_loss: 5.9444\n",
      "Epoch 964/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.2754 - val_loss: 6.7580\n",
      "Epoch 965/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.7102 - val_loss: 7.2173\n",
      "Epoch 966/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 4.0033 - val_loss: 5.9602\n",
      "Epoch 967/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.4394 - val_loss: 7.4040\n",
      "Epoch 968/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5803 - val_loss: 6.9420\n",
      "Epoch 969/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.5338 - val_loss: 6.5057\n",
      "Epoch 970/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.4245 - val_loss: 5.8433\n",
      "Epoch 971/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.6362 - val_loss: 6.3882\n",
      "Epoch 972/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 3.4746 - val_loss: 5.9967\n",
      "Epoch 973/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.6419 - val_loss: 5.7507\n",
      "Epoch 974/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5242 - val_loss: 6.2599\n",
      "Epoch 975/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.6628 - val_loss: 5.8487\n",
      "Epoch 976/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.4278 - val_loss: 6.6576\n",
      "Epoch 977/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.5412 - val_loss: 7.1695\n",
      "Epoch 978/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5955 - val_loss: 5.5972\n",
      "Epoch 979/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.3925 - val_loss: 5.7163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.7316 - val_loss: 7.9669\n",
      "Epoch 981/1000\n",
      "1953/1953 [==============================] - 0s 102us/step - loss: 3.4584 - val_loss: 5.8741\n",
      "Epoch 982/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.2691 - val_loss: 5.9485\n",
      "Epoch 983/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.3815 - val_loss: 6.0660\n",
      "Epoch 984/1000\n",
      "1953/1953 [==============================] - 0s 108us/step - loss: 3.6449 - val_loss: 7.4769\n",
      "Epoch 985/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.4481 - val_loss: 5.8468\n",
      "Epoch 986/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.2750 - val_loss: 6.3425\n",
      "Epoch 987/1000\n",
      "1953/1953 [==============================] - 0s 109us/step - loss: 3.6331 - val_loss: 6.1131\n",
      "Epoch 988/1000\n",
      "1953/1953 [==============================] - 0s 110us/step - loss: 3.3974 - val_loss: 5.7860\n",
      "Epoch 989/1000\n",
      "1953/1953 [==============================] - 0s 112us/step - loss: 3.5609 - val_loss: 6.1178\n",
      "Epoch 990/1000\n",
      "1953/1953 [==============================] - 0s 115us/step - loss: 3.4445 - val_loss: 5.9898\n",
      "Epoch 991/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.2487 - val_loss: 6.6110\n",
      "Epoch 992/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.4288 - val_loss: 6.0133\n",
      "Epoch 993/1000\n",
      "1953/1953 [==============================] - 0s 103us/step - loss: 3.5017 - val_loss: 7.1464\n",
      "Epoch 994/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5563 - val_loss: 5.6877\n",
      "Epoch 995/1000\n",
      "1953/1953 [==============================] - 0s 106us/step - loss: 3.4418 - val_loss: 6.1652\n",
      "Epoch 996/1000\n",
      "1953/1953 [==============================] - 0s 104us/step - loss: 3.4290 - val_loss: 6.2342\n",
      "Epoch 997/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.3627 - val_loss: 5.7582\n",
      "Epoch 998/1000\n",
      "1953/1953 [==============================] - 0s 107us/step - loss: 3.5911 - val_loss: 5.8918\n",
      "Epoch 999/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5257 - val_loss: 5.9088\n",
      "Epoch 1000/1000\n",
      "1953/1953 [==============================] - 0s 105us/step - loss: 3.5458 - val_loss: 6.4278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3f128f98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = buildToOneModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=100, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=20, validation_data=(X_valid, y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "212/212 [==============================] - 0s 23us/step\n",
      "test loss, test acc: 638.8241081957547\n",
      "\n",
      "# Generate predictions for 3 samples\n",
      "predictions shape: (212, 1)\n",
      "rmse: 25.274970340294928\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(X_test_batches, Y_test_batches, batch_size=128)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(X_test_batches)\n",
    "print('predictions shape:', predictions.shape)\n",
    "\n",
    "\n",
    "rmse=np.sqrt(np.mean(((predictions- Y_test_batches)**2)))\n",
    "print('rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>true_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.100784</td>\n",
       "      <td>174.869995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.080048</td>\n",
       "      <td>173.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172.847549</td>\n",
       "      <td>174.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.487030</td>\n",
       "      <td>175.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.716095</td>\n",
       "      <td>175.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>219.969269</td>\n",
       "      <td>279.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>216.498581</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>211.843597</td>\n",
       "      <td>284.269989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>215.150787</td>\n",
       "      <td>289.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>218.172043</td>\n",
       "      <td>289.799988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction  true_value\n",
       "0    172.100784  174.869995\n",
       "1    172.080048  173.149994\n",
       "2    172.847549  174.970001\n",
       "3    169.487030  175.850006\n",
       "4    170.716095  175.529999\n",
       "..          ...         ...\n",
       "207  219.969269  279.440002\n",
       "208  216.498581  284.000000\n",
       "209  211.843597  284.269989\n",
       "210  215.150787  289.910004\n",
       "211  218.172043  289.799988\n",
       "\n",
       "[212 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictFrame = pd.DataFrame({'prediction': predictions.reshape(X_test_batches.shape[0]), 'true_value': Y_test_batches.reshape(X_test_batches.shape[0])})\n",
    "predictFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('1-day Delta ($)', fontsize=18)\n",
    "plt.plot(predictFrame)\n",
    "plt.legend(['prediction', 'true_value'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
